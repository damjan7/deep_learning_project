{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import Subset\n",
    "from torch.distributions import Categorical, Normal, StudentT\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import calibration_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import deque, OrderedDict\n",
    "from tqdm import trange\n",
    "import tqdm\n",
    "import copy\n",
    "import typing\n",
    "from typing import Sequence, Optional, Callable, Tuple, Dict, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Priors import IsotropicGaussian, StudentTPrior, LaplacePrior, InverseGamma, GaussianMixture, MixedLaplaceUniform, MixedLU\n",
    "from Networks import FullyConnectedNN, ConvolutionalNN\n",
    "from BayesianNN import BayesianNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "transform = transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample from trainset\n",
    "n_subsamples_train = 2000 # size of subset\n",
    "sub_train_idx = random.sample(range(60000),n_subsamples_train)\n",
    "sub_train_set = Subset(train_set, sub_train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Modelihno\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.08it/s, acc=0.281, log_prior_normalized=0.92, loss=8.25e+4, lr=0.000316, nll_loss=34.3]\n"
     ]
    }
   ],
   "source": [
    "lol = BayesianNN(sub_train_set,network = FullyConnectedNN(), prior=IsotropicGaussian(), num_epochs=10)\n",
    "lol.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17f2fa85e4cfd485d54f024c1b8a04817ed39643e0edc5d72a4881a916b82e72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
