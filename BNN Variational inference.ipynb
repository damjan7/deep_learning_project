{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as dist\n",
    "import abc\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions.distribution import Distribution\n",
    "\n",
    "from priors import *\n",
    "from models import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: jorgefernando17. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jorge\\OneDrive\\Dokumente\\Universit√§t\\Master\\HS22\\Deep Learning\\Project\\Coding\\wandb\\run-20221230_150018-qdhwqytd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jorgefernando17/BNN_VI/runs/qdhwqytd\" target=\"_blank\">likely-snowflake-50</a></strong> to <a href=\"https://wandb.ai/jorgefernando17/BNN_VI\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jorgefernando17/BNN_VI/runs/qdhwqytd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1d02e51fbe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only run this cell if you use weights and biases for logging\n",
    "import wandb\n",
    "\n",
    "wandb.init(project = \"BNN_VI\", \n",
    "            config = {\"learning_rate\": 0.001,\n",
    "                      \"batch_size\": 128,\n",
    "                      \"epochs\": 10,\n",
    "                      \"hidden_size\": 100,})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "x_train = torch.from_numpy(trainset.data.numpy().reshape(-1, 28*28))/255.\n",
    "y_train = torch.from_numpy(trainset.targets.numpy())\n",
    "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "x_test = torch.from_numpy(testset.data.numpy().reshape(-1, 28*28))/255.\n",
    "y_test = torch.from_numpy(testset.targets.numpy())\n",
    "test_data = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature = trainset[0][0]\n",
    "label = trainset[0][1]\n",
    "print(label)\n",
    "plt.imshow(feature.squeeze(), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian_Neural_Network(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear_Layer(\n",
      "      (weight_prior): MultivariateDiagonalGaussian()\n",
      "      (bias_prior): MultivariateDiagonalGaussian()\n",
      "      (weight_posterior): MultivariateDiagonalGaussian()\n",
      "      (bias_posterior): MultivariateDiagonalGaussian()\n",
      "    )\n",
      "    (1): Linear_Layer(\n",
      "      (weight_prior): MultivariateDiagonalGaussian()\n",
      "      (bias_prior): MultivariateDiagonalGaussian()\n",
      "      (weight_posterior): MultivariateDiagonalGaussian()\n",
      "      (bias_posterior): MultivariateDiagonalGaussian()\n",
      "    )\n",
      "  )\n",
      "  (activation): ReLU(inplace=True)\n",
      ")\n",
      "Epoch: 0 | Batch: 0 | Loss: -6.3973188400268555, accuracy: 0.078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:371: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch: 100 | Loss: -6.301070690155029, accuracy: 0.078125\n",
      "Epoch: 0 | Batch: 200 | Loss: -7.221643924713135, accuracy: 0.0625\n",
      "Epoch: 0 | Batch: 300 | Loss: -7.862584114074707, accuracy: 0.078125\n",
      "Epoch: 0 | Batch: 400 | Loss: -4.526492118835449, accuracy: 0.078125\n",
      "Epoch: 0 | Batch: 500 | Loss: -8.554241180419922, accuracy: 0.046875\n",
      "Epoch: 0 | Batch: 600 | Loss: -6.257596969604492, accuracy: 0.0625\n",
      "Epoch: 0 | Batch: 700 | Loss: -7.351167678833008, accuracy: 0.109375\n",
      "Epoch: 0 | Batch: 800 | Loss: -7.940821647644043, accuracy: 0.09375\n",
      "Epoch: 0 | Batch: 900 | Loss: -9.762059211730957, accuracy: 0.140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 1/20 [00:36<11:32, 36.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 0 | Loss: -11.916516304016113, accuracy: 0.140625\n",
      "Epoch: 1 | Batch: 100 | Loss: -10.853055953979492, accuracy: 0.25\n",
      "Epoch: 1 | Batch: 200 | Loss: -7.829953193664551, accuracy: 0.140625\n",
      "Epoch: 1 | Batch: 300 | Loss: -12.306503295898438, accuracy: 0.21875\n",
      "Epoch: 1 | Batch: 400 | Loss: -17.558259963989258, accuracy: 0.28125\n",
      "Epoch: 1 | Batch: 500 | Loss: -18.18385124206543, accuracy: 0.390625\n",
      "Epoch: 1 | Batch: 600 | Loss: -17.349580764770508, accuracy: 0.25\n",
      "Epoch: 1 | Batch: 700 | Loss: -16.945018768310547, accuracy: 0.296875\n",
      "Epoch: 1 | Batch: 800 | Loss: -19.328006744384766, accuracy: 0.3125\n",
      "Epoch: 1 | Batch: 900 | Loss: -25.740310668945312, accuracy: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 2/20 [01:13<10:57, 36.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Batch: 0 | Loss: -22.372854232788086, accuracy: 0.375\n",
      "Epoch: 2 | Batch: 100 | Loss: -23.944551467895508, accuracy: 0.359375\n",
      "Epoch: 2 | Batch: 200 | Loss: -25.000951766967773, accuracy: 0.421875\n",
      "Epoch: 2 | Batch: 300 | Loss: -27.304290771484375, accuracy: 0.515625\n",
      "Epoch: 2 | Batch: 400 | Loss: -22.011415481567383, accuracy: 0.3125\n",
      "Epoch: 2 | Batch: 500 | Loss: -35.254302978515625, accuracy: 0.546875\n",
      "Epoch: 2 | Batch: 600 | Loss: -29.526424407958984, accuracy: 0.4375\n",
      "Epoch: 2 | Batch: 700 | Loss: -29.334636688232422, accuracy: 0.4375\n",
      "Epoch: 2 | Batch: 800 | Loss: -29.50534439086914, accuracy: 0.5\n",
      "Epoch: 2 | Batch: 900 | Loss: -32.483070373535156, accuracy: 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 3/20 [01:50<10:27, 36.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Batch: 0 | Loss: -29.716533660888672, accuracy: 0.484375\n",
      "Epoch: 3 | Batch: 100 | Loss: -27.89259910583496, accuracy: 0.390625\n",
      "Epoch: 3 | Batch: 200 | Loss: -32.701961517333984, accuracy: 0.515625\n",
      "Epoch: 3 | Batch: 300 | Loss: -34.07322692871094, accuracy: 0.546875\n",
      "Epoch: 3 | Batch: 400 | Loss: -37.71000289916992, accuracy: 0.671875\n",
      "Epoch: 3 | Batch: 500 | Loss: -30.491844177246094, accuracy: 0.46875\n",
      "Epoch: 3 | Batch: 600 | Loss: -31.065746307373047, accuracy: 0.53125\n",
      "Epoch: 3 | Batch: 700 | Loss: -29.98563003540039, accuracy: 0.46875\n",
      "Epoch: 3 | Batch: 800 | Loss: -28.453388214111328, accuracy: 0.40625\n",
      "Epoch: 3 | Batch: 900 | Loss: -38.87080383300781, accuracy: 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 4/20 [02:28<09:51, 36.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Batch: 0 | Loss: -39.45369338989258, accuracy: 0.59375\n",
      "Epoch: 4 | Batch: 100 | Loss: -33.44032287597656, accuracy: 0.46875\n",
      "Epoch: 4 | Batch: 200 | Loss: -34.574520111083984, accuracy: 0.625\n",
      "Epoch: 4 | Batch: 300 | Loss: -40.39591979980469, accuracy: 0.671875\n",
      "Epoch: 4 | Batch: 400 | Loss: -37.52743911743164, accuracy: 0.5625\n",
      "Epoch: 4 | Batch: 500 | Loss: -35.68455123901367, accuracy: 0.53125\n",
      "Epoch: 4 | Batch: 600 | Loss: -38.02777862548828, accuracy: 0.546875\n",
      "Epoch: 4 | Batch: 700 | Loss: -35.00877380371094, accuracy: 0.53125\n",
      "Epoch: 4 | Batch: 800 | Loss: -36.86738586425781, accuracy: 0.640625\n",
      "Epoch: 4 | Batch: 900 | Loss: -37.5993537902832, accuracy: 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 5/20 [03:05<09:15, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Batch: 0 | Loss: -34.21814727783203, accuracy: 0.515625\n",
      "Epoch: 5 | Batch: 100 | Loss: -38.61834716796875, accuracy: 0.625\n",
      "Epoch: 5 | Batch: 200 | Loss: -38.16630554199219, accuracy: 0.59375\n",
      "Epoch: 5 | Batch: 300 | Loss: -36.90756607055664, accuracy: 0.5625\n",
      "Epoch: 5 | Batch: 400 | Loss: -33.759788513183594, accuracy: 0.53125\n",
      "Epoch: 5 | Batch: 500 | Loss: -37.15797424316406, accuracy: 0.59375\n",
      "Epoch: 5 | Batch: 600 | Loss: -37.21946334838867, accuracy: 0.5625\n",
      "Epoch: 5 | Batch: 700 | Loss: -39.7788200378418, accuracy: 0.515625\n",
      "Epoch: 5 | Batch: 800 | Loss: -37.977596282958984, accuracy: 0.578125\n",
      "Epoch: 5 | Batch: 900 | Loss: -38.8983268737793, accuracy: 0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 6/20 [03:42<08:38, 37.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Batch: 0 | Loss: -34.523189544677734, accuracy: 0.546875\n",
      "Epoch: 6 | Batch: 100 | Loss: -43.572662353515625, accuracy: 0.671875\n",
      "Epoch: 6 | Batch: 200 | Loss: -40.68378829956055, accuracy: 0.671875\n",
      "Epoch: 6 | Batch: 300 | Loss: -38.25208282470703, accuracy: 0.625\n",
      "Epoch: 6 | Batch: 400 | Loss: -41.50362777709961, accuracy: 0.703125\n",
      "Epoch: 6 | Batch: 500 | Loss: -42.07778549194336, accuracy: 0.53125\n",
      "Epoch: 6 | Batch: 600 | Loss: -39.330448150634766, accuracy: 0.59375\n",
      "Epoch: 6 | Batch: 700 | Loss: -39.5341911315918, accuracy: 0.625\n",
      "Epoch: 6 | Batch: 800 | Loss: -41.1464958190918, accuracy: 0.640625\n",
      "Epoch: 6 | Batch: 900 | Loss: -44.15753936767578, accuracy: 0.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 7/20 [04:19<08:02, 37.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Batch: 0 | Loss: -41.303619384765625, accuracy: 0.6875\n",
      "Epoch: 7 | Batch: 100 | Loss: -38.71277618408203, accuracy: 0.609375\n",
      "Epoch: 7 | Batch: 200 | Loss: -40.79195022583008, accuracy: 0.59375\n",
      "Epoch: 7 | Batch: 300 | Loss: -38.95117950439453, accuracy: 0.546875\n",
      "Epoch: 7 | Batch: 400 | Loss: -37.309810638427734, accuracy: 0.546875\n",
      "Epoch: 7 | Batch: 500 | Loss: -41.10463333129883, accuracy: 0.609375\n",
      "Epoch: 7 | Batch: 600 | Loss: -39.81050491333008, accuracy: 0.609375\n",
      "Epoch: 7 | Batch: 700 | Loss: -43.43872833251953, accuracy: 0.625\n",
      "Epoch: 7 | Batch: 800 | Loss: -44.22022247314453, accuracy: 0.6875\n",
      "Epoch: 7 | Batch: 900 | Loss: -46.14548110961914, accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 8/20 [04:56<07:24, 37.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Batch: 0 | Loss: -44.20046615600586, accuracy: 0.6875\n",
      "Epoch: 8 | Batch: 100 | Loss: -48.82688522338867, accuracy: 0.75\n",
      "Epoch: 8 | Batch: 200 | Loss: -43.23630905151367, accuracy: 0.703125\n",
      "Epoch: 8 | Batch: 300 | Loss: -44.202880859375, accuracy: 0.703125\n",
      "Epoch: 8 | Batch: 400 | Loss: -50.46117401123047, accuracy: 0.796875\n",
      "Epoch: 8 | Batch: 500 | Loss: -47.500091552734375, accuracy: 0.78125\n",
      "Epoch: 8 | Batch: 600 | Loss: -50.715187072753906, accuracy: 0.828125\n",
      "Epoch: 8 | Batch: 700 | Loss: -43.41500473022461, accuracy: 0.671875\n",
      "Epoch: 8 | Batch: 800 | Loss: -42.70781326293945, accuracy: 0.65625\n",
      "Epoch: 8 | Batch: 900 | Loss: -42.911415100097656, accuracy: 0.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 9/20 [05:40<07:09, 39.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Batch: 0 | Loss: -54.02680206298828, accuracy: 0.875\n",
      "Epoch: 9 | Batch: 100 | Loss: -47.21923065185547, accuracy: 0.734375\n",
      "Epoch: 9 | Batch: 200 | Loss: -46.63798522949219, accuracy: 0.75\n",
      "Epoch: 9 | Batch: 300 | Loss: -45.933807373046875, accuracy: 0.671875\n",
      "Epoch: 9 | Batch: 400 | Loss: -51.24456024169922, accuracy: 0.8125\n",
      "Epoch: 9 | Batch: 500 | Loss: -48.6260986328125, accuracy: 0.78125\n",
      "Epoch: 9 | Batch: 600 | Loss: -42.07912826538086, accuracy: 0.625\n",
      "Epoch: 9 | Batch: 700 | Loss: -48.82219314575195, accuracy: 0.75\n",
      "Epoch: 9 | Batch: 800 | Loss: -45.37215805053711, accuracy: 0.75\n",
      "Epoch: 9 | Batch: 900 | Loss: -42.98170471191406, accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10/20 [06:16<06:23, 38.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Batch: 0 | Loss: -48.77046585083008, accuracy: 0.75\n",
      "Epoch: 10 | Batch: 100 | Loss: -45.89835739135742, accuracy: 0.703125\n",
      "Epoch: 10 | Batch: 200 | Loss: -44.43727111816406, accuracy: 0.71875\n",
      "Epoch: 10 | Batch: 300 | Loss: -45.588836669921875, accuracy: 0.71875\n",
      "Epoch: 10 | Batch: 400 | Loss: -46.04008483886719, accuracy: 0.75\n",
      "Epoch: 10 | Batch: 500 | Loss: -48.715057373046875, accuracy: 0.765625\n",
      "Epoch: 10 | Batch: 600 | Loss: -47.97568893432617, accuracy: 0.765625\n",
      "Epoch: 10 | Batch: 700 | Loss: -49.73405075073242, accuracy: 0.765625\n",
      "Epoch: 10 | Batch: 800 | Loss: -44.85333251953125, accuracy: 0.71875\n",
      "Epoch: 10 | Batch: 900 | Loss: -47.16593933105469, accuracy: 0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 11/20 [06:55<05:44, 38.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Batch: 0 | Loss: -47.761009216308594, accuracy: 0.765625\n",
      "Epoch: 11 | Batch: 100 | Loss: -48.64368438720703, accuracy: 0.71875\n",
      "Epoch: 11 | Batch: 200 | Loss: -49.61689758300781, accuracy: 0.828125\n",
      "Epoch: 11 | Batch: 300 | Loss: -48.168128967285156, accuracy: 0.75\n",
      "Epoch: 11 | Batch: 400 | Loss: -50.177425384521484, accuracy: 0.75\n",
      "Epoch: 11 | Batch: 500 | Loss: -45.818939208984375, accuracy: 0.734375\n",
      "Epoch: 11 | Batch: 600 | Loss: -53.62003707885742, accuracy: 0.859375\n",
      "Epoch: 11 | Batch: 700 | Loss: -47.99363327026367, accuracy: 0.71875\n",
      "Epoch: 11 | Batch: 800 | Loss: -49.17816925048828, accuracy: 0.8125\n",
      "Epoch: 11 | Batch: 900 | Loss: -46.13200378417969, accuracy: 0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12/20 [07:32<05:03, 37.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Batch: 0 | Loss: -48.565269470214844, accuracy: 0.765625\n",
      "Epoch: 12 | Batch: 100 | Loss: -49.985679626464844, accuracy: 0.828125\n",
      "Epoch: 12 | Batch: 200 | Loss: -47.17429733276367, accuracy: 0.78125\n",
      "Epoch: 12 | Batch: 300 | Loss: -50.146080017089844, accuracy: 0.796875\n",
      "Epoch: 12 | Batch: 400 | Loss: -51.67625427246094, accuracy: 0.8125\n",
      "Epoch: 12 | Batch: 500 | Loss: -49.76898193359375, accuracy: 0.75\n",
      "Epoch: 12 | Batch: 600 | Loss: -53.565399169921875, accuracy: 0.859375\n",
      "Epoch: 12 | Batch: 700 | Loss: -48.26344299316406, accuracy: 0.84375\n",
      "Epoch: 12 | Batch: 800 | Loss: -52.90101623535156, accuracy: 0.859375\n",
      "Epoch: 12 | Batch: 900 | Loss: -50.76488494873047, accuracy: 0.78125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 13/20 [08:08<04:21, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Batch: 0 | Loss: -51.12575912475586, accuracy: 0.796875\n",
      "Epoch: 13 | Batch: 100 | Loss: -49.42121124267578, accuracy: 0.765625\n",
      "Epoch: 13 | Batch: 200 | Loss: -49.265235900878906, accuracy: 0.8125\n",
      "Epoch: 13 | Batch: 300 | Loss: -53.684967041015625, accuracy: 0.90625\n",
      "Epoch: 13 | Batch: 400 | Loss: -47.0445442199707, accuracy: 0.71875\n",
      "Epoch: 13 | Batch: 500 | Loss: -50.75263977050781, accuracy: 0.859375\n",
      "Epoch: 13 | Batch: 600 | Loss: -51.32570266723633, accuracy: 0.8125\n",
      "Epoch: 13 | Batch: 700 | Loss: -49.8357048034668, accuracy: 0.78125\n",
      "Epoch: 13 | Batch: 800 | Loss: -47.52338409423828, accuracy: 0.828125\n",
      "Epoch: 13 | Batch: 900 | Loss: -51.52207946777344, accuracy: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14/20 [08:44<03:42, 37.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Batch: 0 | Loss: -51.29812240600586, accuracy: 0.84375\n",
      "Epoch: 14 | Batch: 100 | Loss: -54.43742370605469, accuracy: 0.828125\n",
      "Epoch: 14 | Batch: 200 | Loss: -55.21271514892578, accuracy: 0.890625\n",
      "Epoch: 14 | Batch: 300 | Loss: -49.902976989746094, accuracy: 0.78125\n",
      "Epoch: 14 | Batch: 400 | Loss: -54.10249328613281, accuracy: 0.84375\n",
      "Epoch: 14 | Batch: 500 | Loss: -51.52429962158203, accuracy: 0.828125\n",
      "Epoch: 14 | Batch: 600 | Loss: -54.460487365722656, accuracy: 0.84375\n",
      "Epoch: 14 | Batch: 700 | Loss: -49.27388000488281, accuracy: 0.734375\n",
      "Epoch: 14 | Batch: 800 | Loss: -48.02692413330078, accuracy: 0.796875\n",
      "Epoch: 14 | Batch: 900 | Loss: -56.785858154296875, accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 15/20 [09:20<03:03, 36.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Batch: 0 | Loss: -52.74568176269531, accuracy: 0.84375\n",
      "Epoch: 15 | Batch: 100 | Loss: -49.071929931640625, accuracy: 0.8125\n",
      "Epoch: 15 | Batch: 200 | Loss: -55.509437561035156, accuracy: 0.90625\n",
      "Epoch: 15 | Batch: 300 | Loss: -52.7083625793457, accuracy: 0.890625\n",
      "Epoch: 15 | Batch: 400 | Loss: -53.744876861572266, accuracy: 0.828125\n",
      "Epoch: 15 | Batch: 500 | Loss: -50.44361877441406, accuracy: 0.71875\n",
      "Epoch: 15 | Batch: 600 | Loss: -53.505104064941406, accuracy: 0.875\n",
      "Epoch: 15 | Batch: 700 | Loss: -48.53441619873047, accuracy: 0.6875\n",
      "Epoch: 15 | Batch: 800 | Loss: -50.10051345825195, accuracy: 0.75\n",
      "Epoch: 15 | Batch: 900 | Loss: -54.64799118041992, accuracy: 0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 16/20 [09:57<02:26, 36.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Batch: 0 | Loss: -52.58565902709961, accuracy: 0.859375\n",
      "Epoch: 16 | Batch: 100 | Loss: -48.48665237426758, accuracy: 0.71875\n",
      "Epoch: 16 | Batch: 200 | Loss: -51.29352951049805, accuracy: 0.828125\n",
      "Epoch: 16 | Batch: 300 | Loss: -51.27625274658203, accuracy: 0.828125\n",
      "Epoch: 16 | Batch: 400 | Loss: -54.930877685546875, accuracy: 0.875\n",
      "Epoch: 16 | Batch: 500 | Loss: -53.976318359375, accuracy: 0.859375\n",
      "Epoch: 16 | Batch: 600 | Loss: -50.346282958984375, accuracy: 0.78125\n",
      "Epoch: 16 | Batch: 700 | Loss: -53.904441833496094, accuracy: 0.859375\n",
      "Epoch: 16 | Batch: 800 | Loss: -49.68659973144531, accuracy: 0.78125\n",
      "Epoch: 16 | Batch: 900 | Loss: -52.489288330078125, accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 17/20 [10:40<01:56, 38.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Batch: 0 | Loss: -53.68574523925781, accuracy: 0.90625\n",
      "Epoch: 17 | Batch: 100 | Loss: -55.880943298339844, accuracy: 0.921875\n",
      "Epoch: 17 | Batch: 200 | Loss: -55.51476287841797, accuracy: 0.90625\n",
      "Epoch: 17 | Batch: 300 | Loss: -52.62114715576172, accuracy: 0.859375\n",
      "Epoch: 17 | Batch: 400 | Loss: -55.49917984008789, accuracy: 0.890625\n",
      "Epoch: 17 | Batch: 500 | Loss: -51.8929328918457, accuracy: 0.71875\n",
      "Epoch: 17 | Batch: 600 | Loss: -55.29331588745117, accuracy: 0.921875\n",
      "Epoch: 17 | Batch: 700 | Loss: -48.94095230102539, accuracy: 0.78125\n",
      "Epoch: 17 | Batch: 800 | Loss: -49.25160217285156, accuracy: 0.671875\n",
      "Epoch: 17 | Batch: 900 | Loss: -52.51740646362305, accuracy: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 18/20 [11:17<01:16, 38.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Batch: 0 | Loss: -54.84935760498047, accuracy: 0.84375\n",
      "Epoch: 18 | Batch: 100 | Loss: -49.683013916015625, accuracy: 0.765625\n",
      "Epoch: 18 | Batch: 200 | Loss: -48.627906799316406, accuracy: 0.75\n",
      "Epoch: 18 | Batch: 300 | Loss: -53.77875518798828, accuracy: 0.84375\n",
      "Epoch: 18 | Batch: 400 | Loss: -49.86743927001953, accuracy: 0.765625\n",
      "Epoch: 18 | Batch: 500 | Loss: -53.90024948120117, accuracy: 0.859375\n",
      "Epoch: 18 | Batch: 600 | Loss: -50.647438049316406, accuracy: 0.8125\n",
      "Epoch: 18 | Batch: 700 | Loss: -49.59065246582031, accuracy: 0.796875\n",
      "Epoch: 18 | Batch: 800 | Loss: -54.45458221435547, accuracy: 0.875\n",
      "Epoch: 18 | Batch: 900 | Loss: -51.49921417236328, accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [11:54<00:37, 37.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Batch: 0 | Loss: -54.289588928222656, accuracy: 0.84375\n",
      "Epoch: 19 | Batch: 100 | Loss: -57.71244812011719, accuracy: 0.875\n",
      "Epoch: 19 | Batch: 200 | Loss: -53.26166534423828, accuracy: 0.875\n",
      "Epoch: 19 | Batch: 300 | Loss: -47.432945251464844, accuracy: 0.71875\n",
      "Epoch: 19 | Batch: 400 | Loss: -56.24534606933594, accuracy: 0.890625\n",
      "Epoch: 19 | Batch: 500 | Loss: -52.31257247924805, accuracy: 0.859375\n",
      "Epoch: 19 | Batch: 600 | Loss: -50.28647994995117, accuracy: 0.796875\n",
      "Epoch: 19 | Batch: 700 | Loss: -54.62820816040039, accuracy: 0.84375\n",
      "Epoch: 19 | Batch: 800 | Loss: -55.53055191040039, accuracy: 0.90625\n",
      "Epoch: 19 | Batch: 900 | Loss: -52.25679016113281, accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [12:31<00:00, 37.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# create the Bayesian Neural Network\n",
    "model = Bayesian_Neural_Network(input_dim = 28*28, output_dim = 10, hidden_dims = [100])\n",
    "print(model)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.99)\n",
    "\n",
    "# train the model\n",
    "epochs = 20\n",
    "num_samples = 5\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    num_batches = len(train_loader)\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # reshape the data\n",
    "        x = x.view(-1, 28*28)\n",
    "\n",
    "        # reset loss\n",
    "        loss = torch.tensor(0.0)\n",
    "\n",
    "        # forward pass\n",
    "        for e in range(num_samples):\n",
    "            output, kl_divergence = model(x)\n",
    "            loss += (F.nll_loss(F.softmax(output, dim = 1), y, reduction = \"sum\") + kl_divergence/num_batches)/num_samples\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accuracy\n",
    "        acc = torch.mean((torch.argmax(F.softmax(output, dim = 1), dim = 1) == y).float())\n",
    "\n",
    "        # print the loss\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Batch: {i} | Loss: {loss.item()}, accuracy: {acc.item()}\")\n",
    "            scheduler.step()\n",
    "            wandb.log({\"loss\": loss.item(), \"accuracy\": acc.item(), \"epoch\": epoch, \"batch\": i})\n",
    "            wandb.log({\"learning_rate\": scheduler.get_lr()[0]})\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9083999991416931\n",
      "tensor([[7, 7],\n",
      "        [2, 2],\n",
      "        [1, 1],\n",
      "        ...,\n",
      "        [4, 4],\n",
      "        [5, 5],\n",
      "        [6, 6]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b9e61f8612f3>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.hstack((torch.tensor(predicted_class).unsqueeze(1), torch.tensor(y_test).unsqueeze(1))))\n"
     ]
    }
   ],
   "source": [
    "# predict class probabilities for the test data\n",
    "predicted_probs = model.predict_probs(x_test, 100)\n",
    "predicted_class = torch.argmax(predicted_probs, axis = 1)\n",
    "\n",
    "accuracy = torch.sum(predicted_class == y_test) / len(y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(torch.hstack((torch.tensor(predicted_class).unsqueeze(1), torch.tensor(y_test).unsqueeze(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece(predicted_probabilities: np.ndarray, labels: np.ndarray, n_bins: int = 30) -> float:\n",
    "    \"\"\"\n",
    "    Computes the Expected Calibration Error (ECE).\n",
    "    Many options are possible; in this implementation, we provide a simple version.\n",
    "    Using a uniform binning scheme on the full range of probabilities, zero\n",
    "    to one, we bin the probabilities of the predicted label only (ignoring\n",
    "    all other probabilities). For the ith bin, we compute the avg predicted\n",
    "    probability, p_i, and the bin's total accuracy, a_i.\n",
    "    We then compute the ith calibration error of the bin, |p_i - a_i|.\n",
    "    The final returned value is the weighted average of calibration errors of each bin.\n",
    "    :param predicted_probabilities: Predicted probabilities, float array of shape (num_samples, num_classes)\n",
    "    :param labels: True labels, int tensor of shape (num_samples,) with each entry in {0, ..., num_classes - 1}\n",
    "    :param n_bins: Number of bins for histogram binning\n",
    "    :return: ECE score as a float\n",
    "    \"\"\"\n",
    "    num_samples, num_classes = predicted_probabilities.shape\n",
    "\n",
    "    # Predictions are the classes with highest probability\n",
    "    predictions = np.argmax(predicted_probabilities, axis=1)\n",
    "    prediction_confidences = predicted_probabilities[range(num_samples), predictions]\n",
    "\n",
    "    # Use uniform bins on the range of probabilities, i.e. closed interval [0.,1.]\n",
    "    bin_upper_edges = np.histogram_bin_edges([], bins=n_bins, range=(0., 1.))\n",
    "    bin_upper_edges = bin_upper_edges[1:]  # bin_upper_edges[0] = 0.\n",
    "\n",
    "    probs_as_bin_num = np.digitize(prediction_confidences, bin_upper_edges)\n",
    "    sums_per_bin = np.bincount(probs_as_bin_num, minlength=n_bins, weights=prediction_confidences)\n",
    "    sums_per_bin = sums_per_bin.astype(np.float32)\n",
    "\n",
    "    total_per_bin = np.bincount(probs_as_bin_num, minlength=n_bins) \\\n",
    "        + np.finfo(sums_per_bin.dtype).eps  # division by zero\n",
    "    avg_prob_per_bin = sums_per_bin / total_per_bin\n",
    "\n",
    "    onehot_labels = np.eye(num_classes)[labels]\n",
    "    accuracies = onehot_labels[range(num_samples), predictions]  # accuracies[i] is 0 or 1\n",
    "    accuracies_per_bin = np.bincount(probs_as_bin_num, weights=accuracies, minlength=n_bins) / total_per_bin\n",
    "\n",
    "    prob_of_being_in_a_bin = total_per_bin / float(num_samples)\n",
    "\n",
    "    ece_ret = np.abs(accuracies_per_bin - avg_prob_per_bin) * prob_of_being_in_a_bin\n",
    "    ece_ret = np.sum(ece_ret)\n",
    "    return float(ece_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>batch</td><td>‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñà</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8125</td></tr><tr><td>batch</td><td>900</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>learning_rate</td><td>0.00066</td></tr><tr><td>loss</td><td>-52.25679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">likely-snowflake-50</strong>: <a href=\"https://wandb.ai/jorgefernando17/BNN_VI/runs/qdhwqytd\" target=\"_blank\">https://wandb.ai/jorgefernando17/BNN_VI/runs/qdhwqytd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221230_150018-qdhwqytd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9412b45e6a57aa9914730508726d49801d3b2c579f461e1fb13c705887a7b1f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
