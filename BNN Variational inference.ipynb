{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ba2cbb4cd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as dist\n",
    "import abc\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions.distribution import Distribution\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from priors import *\n",
    "from models import *\n",
    "from data import *\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jorge\\OneDrive\\Dokumente\\Universit√§t\\Master\\HS22\\Deep Learning\\Project\\Coding\\wandb\\run-20230103_124451-939utj3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jorgefernando17/BNN_VI/runs/939utj3b\" target=\"_blank\">pretty-shadow-76</a></strong> to <a href=\"https://wandb.ai/jorgefernando17/BNN_VI\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jorgefernando17/BNN_VI/runs/939utj3b?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ba320e9e20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only run this cell if you use weights and biases for logging\n",
    "import wandb\n",
    "\n",
    "wandb.init(project = \"BNN_VI\", \n",
    "            config = {\"learning_rate\": 0.001,\n",
    "                      \"batch_size\": 128,\n",
    "                      \"epochs\": 10,\n",
    "                      \"hidden_size\": 100,\n",
    "                      \"Temperature\": 0.1,})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  60000\n",
      "Test data size:  10000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset with specified transforms\n",
    "# always use ToTensor() as first transform\n",
    "# possible transforms: RandomRotation, RandomCrop, GaussianBlur\n",
    "# avoid Normalize (already done), RandomHorizontalFlip (for MNIST), RandomVerticalFlip (for MNIST)\n",
    "transform = tr.Compose([tr.ToTensor()])\n",
    "augmentations = tr.Compose([tr.RandomRotation(15)])\n",
    "\n",
    "dataset = Data(\"MNIST\", augmentations = None)\n",
    "train_data, test_data = dataset.get_data()\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display some images\n",
    "image_index = 0\n",
    "feature = dataset.trainset[image_index][0]\n",
    "# feature = dataset.trainset_extra[image_index][0] # to display images from the augmented dataset\n",
    "label = train_data[0][1]\n",
    "print(label)\n",
    "plt.imshow(feature.squeeze(), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian_Neural_Network(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear_Layer(\n",
      "      (weight_prior): MultivariateDiagonalGaussian()\n",
      "      (bias_prior): MultivariateDiagonalGaussian()\n",
      "      (weight_posterior): MultivariateDiagonalGaussian()\n",
      "      (bias_posterior): MultivariateDiagonalGaussian()\n",
      "    )\n",
      "    (1): Linear_Layer(\n",
      "      (weight_prior): MultivariateDiagonalGaussian()\n",
      "      (bias_prior): MultivariateDiagonalGaussian()\n",
      "      (weight_posterior): MultivariateDiagonalGaussian()\n",
      "      (bias_posterior): MultivariateDiagonalGaussian()\n",
      "    )\n",
      "  )\n",
      "  (activation): ReLU(inplace=True)\n",
      ")\n",
      "Epoch: 0 | Batch: 0 | Loss: -12.32190990447998, accuracy: 0.0546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-1128b8f25693>:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  acc = torch.mean((torch.argmax(F.softmax(output), dim = 1) == y).float())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch: 100 | Loss: -8.726259231567383, accuracy: 0.0703125\n",
      "Epoch: 0 | Batch: 200 | Loss: -15.34184741973877, accuracy: 0.171875\n",
      "Epoch: 0 | Batch: 300 | Loss: -15.213510513305664, accuracy: 0.140625\n",
      "Epoch: 0 | Batch: 400 | Loss: -11.223331451416016, accuracy: 0.0859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:21<03:17, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 0 | Loss: -15.163411140441895, accuracy: 0.1015625\n",
      "Epoch: 1 | Batch: 100 | Loss: -23.074535369873047, accuracy: 0.1796875\n",
      "Epoch: 1 | Batch: 200 | Loss: -25.353748321533203, accuracy: 0.1640625\n",
      "Epoch: 1 | Batch: 300 | Loss: -25.195247650146484, accuracy: 0.203125\n",
      "Epoch: 1 | Batch: 400 | Loss: -33.1973876953125, accuracy: 0.265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:44<02:57, 22.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Batch: 0 | Loss: -30.978076934814453, accuracy: 0.21875\n",
      "Epoch: 2 | Batch: 100 | Loss: -27.104421615600586, accuracy: 0.3046875\n",
      "Epoch: 2 | Batch: 200 | Loss: -33.14254379272461, accuracy: 0.25\n",
      "Epoch: 2 | Batch: 300 | Loss: -39.897308349609375, accuracy: 0.28125\n",
      "Epoch: 2 | Batch: 400 | Loss: -46.80666732788086, accuracy: 0.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [01:07<02:37, 22.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Batch: 0 | Loss: -37.1356315612793, accuracy: 0.296875\n",
      "Epoch: 3 | Batch: 100 | Loss: -45.813133239746094, accuracy: 0.3671875\n",
      "Epoch: 3 | Batch: 200 | Loss: -46.06298828125, accuracy: 0.375\n",
      "Epoch: 3 | Batch: 300 | Loss: -54.29632568359375, accuracy: 0.4609375\n",
      "Epoch: 3 | Batch: 400 | Loss: -50.386112213134766, accuracy: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [01:28<02:11, 21.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Batch: 0 | Loss: -47.839256286621094, accuracy: 0.375\n",
      "Epoch: 4 | Batch: 100 | Loss: -63.325225830078125, accuracy: 0.5\n",
      "Epoch: 4 | Batch: 200 | Loss: -54.123741149902344, accuracy: 0.40625\n",
      "Epoch: 4 | Batch: 300 | Loss: -59.34040069580078, accuracy: 0.4609375\n",
      "Epoch: 4 | Batch: 400 | Loss: -69.49605560302734, accuracy: 0.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [01:49<01:48, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Batch: 0 | Loss: -67.51700592041016, accuracy: 0.5\n",
      "Epoch: 5 | Batch: 100 | Loss: -61.085609436035156, accuracy: 0.484375\n",
      "Epoch: 5 | Batch: 200 | Loss: -74.52915954589844, accuracy: 0.5625\n",
      "Epoch: 5 | Batch: 300 | Loss: -78.53136444091797, accuracy: 0.6484375\n",
      "Epoch: 5 | Batch: 400 | Loss: -73.7992172241211, accuracy: 0.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [02:09<01:24, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Batch: 0 | Loss: -78.27680206298828, accuracy: 0.65625\n",
      "Epoch: 6 | Batch: 100 | Loss: -76.58805847167969, accuracy: 0.5625\n",
      "Epoch: 6 | Batch: 200 | Loss: -67.83426666259766, accuracy: 0.4921875\n",
      "Epoch: 6 | Batch: 300 | Loss: -78.39073944091797, accuracy: 0.609375\n",
      "Epoch: 6 | Batch: 400 | Loss: -79.59170532226562, accuracy: 0.6015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [02:30<01:03, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Batch: 0 | Loss: -81.14752960205078, accuracy: 0.578125\n",
      "Epoch: 7 | Batch: 100 | Loss: -83.19979858398438, accuracy: 0.640625\n",
      "Epoch: 7 | Batch: 200 | Loss: -83.53543090820312, accuracy: 0.609375\n",
      "Epoch: 7 | Batch: 300 | Loss: -86.08779907226562, accuracy: 0.7265625\n",
      "Epoch: 7 | Batch: 400 | Loss: -85.84175109863281, accuracy: 0.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [02:49<00:40, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Batch: 0 | Loss: -86.78038787841797, accuracy: 0.671875\n",
      "Epoch: 8 | Batch: 100 | Loss: -90.73149108886719, accuracy: 0.6796875\n",
      "Epoch: 8 | Batch: 200 | Loss: -87.52864837646484, accuracy: 0.71875\n",
      "Epoch: 8 | Batch: 300 | Loss: -85.2205810546875, accuracy: 0.6875\n",
      "Epoch: 8 | Batch: 400 | Loss: -88.26870727539062, accuracy: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [03:09<00:20, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Batch: 0 | Loss: -94.95698547363281, accuracy: 0.7734375\n",
      "Epoch: 9 | Batch: 100 | Loss: -93.6861572265625, accuracy: 0.6875\n",
      "Epoch: 9 | Batch: 200 | Loss: -100.05695343017578, accuracy: 0.734375\n",
      "Epoch: 9 | Batch: 300 | Loss: -90.21650695800781, accuracy: 0.703125\n",
      "Epoch: 9 | Batch: 400 | Loss: -91.90170288085938, accuracy: 0.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [03:31<00:00, 21.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# set the Temperature\n",
    "Temperature_posterior = 1\n",
    "\n",
    "# create the Bayesian Neural Network\n",
    "model = Bayesian_Neural_Network(input_dim = 28*28, output_dim = 10, hidden_dims = [100], Temperature = Temperature_posterior)\n",
    "print(model)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.99)\n",
    "\n",
    "# train the model\n",
    "epochs = 10\n",
    "num_samples = 5\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    num_batches = len(train_loader)\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # reshape the data\n",
    "        x = x.view(-1, 28*28)\n",
    "\n",
    "        # reset loss\n",
    "        loss = torch.tensor(0.0)\n",
    "\n",
    "        # forward pass\n",
    "        for e in range(num_samples):\n",
    "            output, kl_divergence = model(x)\n",
    "            loss += (F.nll_loss(F.softmax(output, dim = 1), y, reduction = \"sum\") + kl_divergence/num_batches)/num_samples\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accuracy\n",
    "        acc = torch.mean(torch.argmax(F.softmax(output, dim = 1) == y).float())\n",
    "\n",
    "        # print the loss\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Batch: {i} | Loss: {loss.item()}, accuracy: {acc.item()}\")\n",
    "            scheduler.step()\n",
    "            wandb.log({\"loss\": loss.item(), \"accuracy\": acc.item(), \"epoch\": epoch, \"batch\": i})\n",
    "            wandb.log({\"learning_rate\": scheduler.get_lr()[0]})\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8166000247001648\n",
      "tensor([[7, 7],\n",
      "        [2, 2],\n",
      "        [1, 1],\n",
      "        ...,\n",
      "        [4, 4],\n",
      "        [8, 5],\n",
      "        [6, 6]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-64b81a5d0e6c>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.hstack((torch.tensor(predicted_class).unsqueeze(1), torch.tensor(y_test).unsqueeze(1))))\n"
     ]
    }
   ],
   "source": [
    "# predict class probabilities for the test data\n",
    "x_test = test_data[:][0].clone().detach()\n",
    "y_test = test_data[:][1].clone().detach()\n",
    "\n",
    "predicted_probs = model.predict_probs(x_test, 100)\n",
    "top_probs = torch.max(predicted_probs, axis = 1)\n",
    "predicted_class = torch.argmax(predicted_probs, axis = 1)\n",
    "\n",
    "accuracy = torch.sum(predicted_class == y_test) / len(y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(torch.hstack((torch.tensor(predicted_class).unsqueeze(1), torch.tensor(y_test).unsqueeze(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece(predicted_probabilities: np.ndarray, labels: np.ndarray, n_bins: int = 30) -> float:\n",
    "    \"\"\"\n",
    "    Computes the Expected Calibration Error (ECE).\n",
    "    Many options are possible; in this implementation, we provide a simple version.\n",
    "    Using a uniform binning scheme on the full range of probabilities, zero\n",
    "    to one, we bin the probabilities of the predicted label only (ignoring\n",
    "    all other probabilities). For the ith bin, we compute the avg predicted\n",
    "    probability, p_i, and the bin's total accuracy, a_i.\n",
    "    We then compute the ith calibration error of the bin, |p_i - a_i|.\n",
    "    The final returned value is the weighted average of calibration errors of each bin.\n",
    "    :param predicted_probabilities: Predicted probabilities, float array of shape (num_samples, num_classes)\n",
    "    :param labels: True labels, int tensor of shape (num_samples,) with each entry in {0, ..., num_classes - 1}\n",
    "    :param n_bins: Number of bins for histogram binning\n",
    "    :return: ECE score as a float\n",
    "    \"\"\"\n",
    "    num_samples, num_classes = predicted_probabilities.shape\n",
    "\n",
    "    # Predictions are the classes with highest probability\n",
    "    predictions = np.argmax(predicted_probabilities, axis=1)\n",
    "    prediction_confidences = predicted_probabilities[range(num_samples), predictions]\n",
    "\n",
    "    # Use uniform bins on the range of probabilities, i.e. closed interval [0.,1.]\n",
    "    bin_upper_edges = np.histogram_bin_edges([], bins=n_bins, range=(0., 1.))\n",
    "    bin_upper_edges = bin_upper_edges[1:]  # bin_upper_edges[0] = 0.\n",
    "\n",
    "    probs_as_bin_num = np.digitize(prediction_confidences, bin_upper_edges)\n",
    "    sums_per_bin = np.bincount(probs_as_bin_num, minlength=n_bins, weights=prediction_confidences)\n",
    "    sums_per_bin = sums_per_bin.astype(np.float32)\n",
    "\n",
    "    total_per_bin = np.bincount(probs_as_bin_num, minlength=n_bins) \\\n",
    "        + np.finfo(sums_per_bin.dtype).eps  # division by zero\n",
    "    avg_prob_per_bin = sums_per_bin / total_per_bin\n",
    "\n",
    "    onehot_labels = np.eye(num_classes)[labels]\n",
    "    accuracies = onehot_labels[range(num_samples), predictions]  # accuracies[i] is 0 or 1\n",
    "    accuracies_per_bin = np.bincount(probs_as_bin_num, weights=accuracies, minlength=n_bins) / total_per_bin\n",
    "\n",
    "    prob_of_being_in_a_bin = total_per_bin / float(num_samples)\n",
    "\n",
    "    ece_ret = np.abs(accuracies_per_bin - avg_prob_per_bin) * prob_of_being_in_a_bin\n",
    "    ece_ret = np.sum(ece_ret)\n",
    "    return float(ece_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028179404699802398"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ece(predicted_probs, y_test, n_bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0274)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics.functional import calibration_error\n",
    "\n",
    "calibration_error(predicted_probs, y_test, n_bins = 30, task = \"multiclass\", norm=\"l1\", num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá</td></tr><tr><td>batch</td><td>‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñà</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.67969</td></tr><tr><td>batch</td><td>400</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>learning_rate</td><td>0.00299</td></tr><tr><td>loss</td><td>-91.9017</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eternal-surf-75</strong>: <a href=\"https://wandb.ai/jorgefernando17/BNN_VI/runs/23w44k52\" target=\"_blank\">https://wandb.ai/jorgefernando17/BNN_VI/runs/23w44k52</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230102_195142-23w44k52\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9412b45e6a57aa9914730508726d49801d3b2c579f461e1fb13c705887a7b1f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
