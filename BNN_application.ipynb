{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import Subset\n",
    "from torch.distributions import Categorical, Normal, StudentT\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as tr\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import calibration_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import deque, OrderedDict\n",
    "from tqdm import trange\n",
    "import tqdm\n",
    "import copy\n",
    "import typing\n",
    "from typing import Sequence, Optional, Callable, Tuple, Dict, Union\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "from data import Data\n",
    "from priors import *\n",
    "from Networks import *\n",
    "from BayesianNN import BNN_MCMC\n",
    "from SGLD import SGLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset with specified transforms\n",
    "# possible transforms: RandomRotation, RandomCrop, GaussianBlur\n",
    "# avoid Normalize and ToTensor (already done), RandomHorizontalFlip (for MNIST), RandomVerticalFlip (for MNIST)\n",
    "augmentations = tr.Compose([tr.RandomRotation(15)])\n",
    "\n",
    "train_data, test_data = Data(\"MNIST\", augmentations = None).get_data(num_train_samples=60000)\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Isotropic_Gaussian()\n",
    "lol = BNN_MCMC(\n",
    "    train_data, \n",
    "    network = ConvolutionalNN(), \n",
    "    prior=prior, \n",
    "    num_epochs = 30, \n",
    "    max_size = 15, \n",
    "    burn_in = 5, \n",
    "    lr = 1e-3, \n",
    "    sample_interval = 2, \n",
    "    Temperature = 10)\n",
    "\n",
    "lol.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lol.test_accuracy(test_data)\n",
    "ece = lol.test_calibration(test_data)\n",
    "auroc = lol.test_auroc(test_data)\n",
    "print(\"Test accuracy: \", acc)\n",
    "print(\"Test ECE: \", ece)\n",
    "print(\"Test AUROC: \", auroc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol.get_metrics(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute AUROC\n",
    "x_test = test_data[:][0]\n",
    "y_test = test_data[:][1]    \n",
    "\n",
    "# get prediction probabilities\n",
    "probs = lol.predict_probabilities(x_test)\n",
    "\n",
    "# get argmax of predictions\n",
    "preds = probs.argmax(dim=1)\n",
    "\n",
    "# compute AUROC\n",
    "auroc = roc_auc_score(y_test, probs, multi_class='ovo')\n",
    "\n",
    "auroc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights from all models\n",
    "param_flat_all = []\n",
    "for model in lol.model_sequence:\n",
    "    parameters = model.state_dict()\n",
    "    param_values = list(parameters.values())\n",
    "    param_flat = torch.cat([v.flatten() for v in param_values])\n",
    "    param_flat_all.append(param_flat.flatten())\n",
    "\n",
    "# put all weights in one array\n",
    "params = np.concatenate(param_flat_all)\n",
    "\n",
    "# plot weights\n",
    "plt.hist(params, bins=1000, range=(-4, 4))\n",
    "plt.title(\"Weights of all models, GaussianMixture(-2, 0.5, 2, 0.5) \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, var = Normal_Inverse_Gamma(0, 5, 1, 1).sample(100000)\n",
    "x = x.flatten().numpy()\n",
    "var = var\n",
    "\n",
    "# plot prior samples\n",
    "plt.hist(x, bins=1000, range=(-5, 5))\n",
    "plt.show()\n",
    "\n",
    "# plot prior samples\n",
    "print(var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain on FashionMNIST\n",
    "pretrain_data, pretest_data = Data(\"FashionMNIST\", augmentations = None).get_data(num_train_samples=600)\n",
    "\n",
    "prior = Isotropic_Gaussian()\n",
    "pretrainer = BNN_MCMC(pretrain_data, network = FullyConnectedNN(), prior=prior, num_epochs = 30, max_size = 15, burn_in = 5, lr = 1e-3, sample_interval = 2)\n",
    "pretrainer.train()\n",
    "\n",
    "# get pretrained prior parameters\n",
    "mu, var = pretrainer.get_posterior_stats()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_Isotropic_Gaussian = Isotropic_Gaussian(mu, var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_list = [Isotropic_Gaussian(),\n",
    "              StudentT_prior(),\n",
    "              GaussianSpikeNSlab(),\n",
    "              MixedLaplaceUniform(), \n",
    "              Normal_Inverse_Gamma()]\n",
    "\n",
    "prior_list_v2 = [Isotropic_Gaussian,\n",
    "              StudentT_prior,\n",
    "              GaussianSpikeNSlab,\n",
    "              MixedLaplaceUniform, \n",
    "              Normal_Inverse_Gamma]\n",
    "\n",
    "sample_sizes = [3750, 15000, 60000, 120000]\n",
    "\n",
    "Temperatures = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "\n",
    "prior_list = [] \n",
    "for prior in prior_list_v2:\n",
    "    for temp in Temperatures:\n",
    "        prior_list.append(prior(Temperature=temp))\n",
    "        \n",
    "# prior list is then list of all priors initialized with the correpsonding temperature\n",
    "# [prior1_temp1, prior2_temp1, ..., prior7_temp1, prior1_temp2, prior2_temp2, ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prior</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Burn_in</th>\n",
       "      <th>sample_int</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test ECE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prior Sample Size Epochs Burn_in sample_int Temperature Test Accuracy  \\\n",
       "0    NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "1    NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "2    NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "3    NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "4    NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "..   ...         ...    ...     ...        ...         ...           ...   \n",
       "95   NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "96   NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "97   NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "98   NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "99   NaN         NaN    NaN     NaN        NaN         NaN           NaN   \n",
       "\n",
       "   Test ECE  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "..      ...  \n",
       "95      NaN  \n",
       "96      NaN  \n",
       "97      NaN  \n",
       "98      NaN  \n",
       "99      NaN  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preallocate pandas dataframe for results\n",
    "results = pd.DataFrame(columns = [\"Prior\", \"Sample Size\", \"Epochs\", \"Burn_in\", \"sample_int\", \"Temperature\", \"Test Accuracy\", \"Test ECE\"], index = range(len(prior_list)*len(sample_sizes)))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the experiment for all priors\n",
    "\n",
    "# set seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#create a dict for the different parameter values\n",
    "base_epoch, base_burn_in, base_sample_interval, base_samplesize = 50, 10, 2, sample_sizes[-1]\n",
    "args_dict = [(sample_size, (base_epoch*base_samplesize/sample_size, base_burn_in*base_samplesize/sample_size, base_sample_interval*base_samplesize/sample_size )) for sample_size in sample_sizes]\n",
    "args_dict = dict(args_dict)\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "for n in range(len(sample_sizes)):\n",
    "    # get data\n",
    "    if sample_sizes[n] == 120000:\n",
    "        # if sample size is 120000, use data augmentation\n",
    "        augmentations = tr.Compose([tr.RandomRotation(15)])\n",
    "        train_data, test_data = Data(\"MNIST\", augmentations = augmentations).get_data()\n",
    "    else:\n",
    "        # subsample original train data if sample size is smaller than 120000\n",
    "        train_data, test_data = Data(\"MNIST\", augmentations = None).get_data(num_train_samples=sample_sizes[n])\n",
    "    \n",
    "    for i in range(len(prior_list)):\n",
    "        # get prior\n",
    "        prior = prior_list[i]\n",
    "        print(50*\"-\")\n",
    "        print(\"Iteration: \", iteration, \" of \", len(prior_list)*len(sample_sizes))\n",
    "        iteration += 1\n",
    "        print(\"Prior:       \", prior.name)\n",
    "        print(\"Temperature: \", prior.Temperature.numpy())\n",
    "        print(\"Sample size: \", sample_sizes[n])\n",
    "\n",
    "        print(\"Epoch:       \", args_dict[sample_sizes[n]][0])\n",
    "        print(\"Burn in:     \", args_dict[sample_sizes[n]][1])\n",
    "        print(\"Sample interval: \", args_dict[sample_sizes[n]][2])\n",
    "\n",
    "        # run BNN\n",
    "        model = BNN_MCMC(\n",
    "            train_data,\n",
    "            network = FullyConnectedNN(),\n",
    "            prior=prior,\n",
    "            num_epochs = int(args_dict[sample_sizes[n]][0]),\n",
    "            max_size = 10,\n",
    "            burn_in = int(args_dict[sample_sizes[n]][1]),\n",
    "            lr = 1e-3,\n",
    "            sample_interval = int(args_dict[sample_sizes[n]][2]))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # get test accuracy and ECE\n",
    "        acc = model.test_accuracy(test_data)\n",
    "        ece = model.test_calibration(test_data)\n",
    "\n",
    "        print(\"Test accuracy: \", acc)\n",
    "        print(\"Test ECE: \", ece)\n",
    "\n",
    "        # save results\n",
    "        results.iloc[i+n*len(prior_list), :] = prior.name, sample_sizes[n], args_dict[sample_sizes[n]][0], args_dict[sample_sizes[n]][1], args_dict[sample_sizes[n]][2], prior.Temperature.numpy(), acc, ece\n",
    "\n",
    "        # save model\n",
    "        #torch.save(model, \"models/\"+prior.name+\"_\"+str(sample_sizes[n])+\"_\"+str(prior.Temperature.numpy())+\".pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print full pandas dataframe\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model \n",
    "model = torch.load(\"models/Isotropic Gaussian_3750_1.0.pt\")\n",
    "\n",
    "# get test accuracy and ECE\n",
    "acc = model.test_accuracy(test_data)\n",
    "\n",
    "# get test data\n",
    "x_test = test_data[:][0]\n",
    "y_test = test_data[:][1]\n",
    "\n",
    "preds = model.predict_probabilities(x_test)\n",
    "print(preds.shape)\n",
    "\n",
    "ece = calibration_error(preds, y_test, n_bins = 10, task = \"multiclass\", norm=\"l1\", num_classes=10)\n",
    "\n",
    "\n",
    "print(\"Test accuracy: \", acc)\n",
    "#print(\"Test ECE: \", ece)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create loop fpr a prior at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the prior \n",
    "prior = Isotropic_Gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# network list\n",
    "networks = {\"FCNN\": FullyConnectedNN(),\n",
    "          \"CNN\": ConvolutionalNN()}\n",
    "\n",
    "# Temperature list\n",
    "Temperatures = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# sample size list\n",
    "sample_sizes = [3750, 15000, 60000, 120000]\n",
    "\n",
    "# preallocate pandas dataframe for results\n",
    "results = pd.DataFrame(columns = [\n",
    "    \"Network\", \n",
    "    \"Sample Size\", \n",
    "    \"Epochs\", \n",
    "    \"Burn in\", \n",
    "    \"sample interval\", \n",
    "    \"Temperature\", \n",
    "    \"Test Accuracy\", \n",
    "    \"Test ECE\", \n",
    "    \"Test AUROC\"], \n",
    "    index = range(len(networks)*len(Temperatures)*len(sample_sizes)))\n",
    "\n",
    "\n",
    "#create a dict for the different parameter values\n",
    "base_epoch, base_burn_in, base_sample_interval, base_samplesize = 50, 10, 2, sample_sizes[-1]\n",
    "args_dict = [(sample_size, (base_epoch*base_samplesize/sample_size, base_burn_in*base_samplesize/sample_size, base_sample_interval*base_samplesize/sample_size )) for sample_size in sample_sizes]\n",
    "args_dict = dict(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNN\n",
      "CNN\n"
     ]
    }
   ],
   "source": [
    "args_dict\n",
    "networks.keys()\n",
    "\n",
    "for net in networks.keys():\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/1600 [00:09<07:19,  3.57it/s, acc=0.93, log_prior_normalized=8.27e+4, loss=8.27e+4, lr=0.00099, nll_loss=10.3]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 43\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m# run BNN\u001b[39;00m\n\u001b[0;32m     33\u001b[0m model \u001b[39m=\u001b[39m BNN_MCMC(\n\u001b[0;32m     34\u001b[0m     train_data,\n\u001b[0;32m     35\u001b[0m     network \u001b[39m=\u001b[39m networks[net],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m,\n\u001b[0;32m     41\u001b[0m     sample_interval \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(args_dict[sample_sizes[n]][\u001b[39m2\u001b[39m]))\n\u001b[1;32m---> 43\u001b[0m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     45\u001b[0m \u001b[39m# get test metrics\u001b[39;00m\n\u001b[0;32m     46\u001b[0m acc, ece, auroc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtest_metrics(test_data)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\OneDrive\\Dokumente\\Universität\\Master\\HS22\\Deep Learning\\Project\\Coding\\BayesianNN.py:81\u001b[0m, in \u001b[0;36mBNN_MCMC.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m progress_bar:\n\u001b[0;32m     79\u001b[0m     num_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (batch_x, batch_y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loader):\n\u001b[0;32m     82\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     83\u001b[0m         n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch_x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:670\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:618\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 618\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\sampler.py:254\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m batch \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m    253\u001b[0m idx_in_batch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 254\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler:\n\u001b[0;32m    255\u001b[0m     batch[idx_in_batch] \u001b[39m=\u001b[39m idx\n\u001b[0;32m    256\u001b[0m     idx_in_batch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\sampler.py:133\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n):\n\u001b[0;32m    132\u001b[0m     \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39mrandperm(n, generator\u001b[39m=\u001b[39mgenerator)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m--> 133\u001b[0m \u001b[39myield from\u001b[39;00m torch\u001b[39m.\u001b[39;49mrandperm(n, generator\u001b[39m=\u001b[39;49mgenerator)\u001b[39m.\u001b[39mtolist()[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m%\u001b[39m n]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the experiment for all networks\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for net in networks.keys():\n",
    "    for T in Temperatures:\n",
    "        for n in range(len(sample_sizes)):\n",
    "        \n",
    "            \"\"\" \n",
    "            # print iteration info\n",
    "            print(50*\"-\")\n",
    "            print(\"Iteration: \", iteration, \" of \", len(networks)*len(Temperatures)*len(sample_sizes))\n",
    "            print(\"Network:     \", net)\n",
    "            print(\"Prior:       \", prior.name)\n",
    "            print(\"Temperature: \", T)\n",
    "            print(\"Sample size: \", sample_sizes[n])\n",
    "            print(\"Epoch:       \", args_dict[sample_sizes[n]][0])\n",
    "            print(\"Burn in:     \", args_dict[sample_sizes[n]][1])\n",
    "            print(\"Sample interval: \", args_dict[sample_sizes[n]][2])\n",
    "            \"\"\"\n",
    "\n",
    "            # get data\n",
    "            if sample_sizes[n] == 120000:\n",
    "                # if sample size is 120000, use data augmentation\n",
    "                augmentations = tr.Compose([tr.RandomRotation(15)])\n",
    "                train_data, test_data = Data(\"MNIST\", augmentations = augmentations).get_data()\n",
    "            else:\n",
    "                # subsample original train data if sample size is smaller than 120000\n",
    "                train_data, test_data = Data(\"MNIST\", augmentations = None).get_data(num_train_samples=sample_sizes[n])\n",
    "\n",
    "\n",
    "            # run BNN\n",
    "            model = BNN_MCMC(\n",
    "                train_data,\n",
    "                network = networks[net],\n",
    "                prior=prior,\n",
    "                num_epochs = int(args_dict[sample_sizes[n]][0]),\n",
    "                max_size = 10,\n",
    "                burn_in = int(args_dict[sample_sizes[n]][1]),\n",
    "                lr = 1e-3,\n",
    "                sample_interval = int(args_dict[sample_sizes[n]][2]))\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            # get test metrics\n",
    "            acc, ece, auroc = model.test_metrics(test_data)\n",
    "\n",
    "            #print(\"Test accuracy: \", acc)\n",
    "            #print(\"Test ECE: \", ece)\n",
    "            #print(\"Test AUROC: \", auroc)\n",
    "\n",
    "            # save results\n",
    "            results.iloc[iteration, :] = net, sample_sizes[n], args_dict[sample_sizes[n]][0], args_dict[sample_sizes[n]][1], args_dict[sample_sizes[n]][2], T, acc, ece, auroc\n",
    "            iteration += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Network</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Burn in</th>\n",
       "      <th>sample interval</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test ECE</th>\n",
       "      <th>Test AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FCNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CNN</td>\n",
       "      <td>3750</td>\n",
       "      <td>1600</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CNN</td>\n",
       "      <td>15000</td>\n",
       "      <td>400</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CNN</td>\n",
       "      <td>60000</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CNN</td>\n",
       "      <td>120000</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Network Sample Size Epochs Burn in sample interval Temperature  \\\n",
       "0     FCNN        3750   1600     320              64       0.001   \n",
       "1     FCNN       15000    400      80              16       0.001   \n",
       "2     FCNN       60000    100      20               4       0.001   \n",
       "3     FCNN      120000     50      10               2       0.001   \n",
       "4     FCNN        3750   1600     320              64        0.01   \n",
       "5     FCNN       15000    400      80              16        0.01   \n",
       "6     FCNN       60000    100      20               4        0.01   \n",
       "7     FCNN      120000     50      10               2        0.01   \n",
       "8     FCNN        3750   1600     320              64         0.1   \n",
       "9     FCNN       15000    400      80              16         0.1   \n",
       "10    FCNN       60000    100      20               4         0.1   \n",
       "11    FCNN      120000     50      10               2         0.1   \n",
       "12    FCNN        3750   1600     320              64           1   \n",
       "13    FCNN       15000    400      80              16           1   \n",
       "14    FCNN       60000    100      20               4           1   \n",
       "15    FCNN      120000     50      10               2           1   \n",
       "16    FCNN        3750   1600     320              64          10   \n",
       "17    FCNN       15000    400      80              16          10   \n",
       "18    FCNN       60000    100      20               4          10   \n",
       "19    FCNN      120000     50      10               2          10   \n",
       "20     CNN        3750   1600     320              64       0.001   \n",
       "21     CNN       15000    400      80              16       0.001   \n",
       "22     CNN       60000    100      20               4       0.001   \n",
       "23     CNN      120000     50      10               2       0.001   \n",
       "24     CNN        3750   1600     320              64        0.01   \n",
       "25     CNN       15000    400      80              16        0.01   \n",
       "26     CNN       60000    100      20               4        0.01   \n",
       "27     CNN      120000     50      10               2        0.01   \n",
       "28     CNN        3750   1600     320              64         0.1   \n",
       "29     CNN       15000    400      80              16         0.1   \n",
       "30     CNN       60000    100      20               4         0.1   \n",
       "31     CNN      120000     50      10               2         0.1   \n",
       "32     CNN        3750   1600     320              64           1   \n",
       "33     CNN       15000    400      80              16           1   \n",
       "34     CNN       60000    100      20               4           1   \n",
       "35     CNN      120000     50      10               2           1   \n",
       "36     CNN        3750   1600     320              64          10   \n",
       "37     CNN       15000    400      80              16          10   \n",
       "38     CNN       60000    100      20               4          10   \n",
       "39     CNN      120000     50      10               2          10   \n",
       "\n",
       "   Test Accuracy Test ECE Test AUROC  \n",
       "0              0        0          0  \n",
       "1              0        0          0  \n",
       "2              0        0          0  \n",
       "3              0        0          0  \n",
       "4              0        0          0  \n",
       "5              0        0          0  \n",
       "6              0        0          0  \n",
       "7              0        0          0  \n",
       "8              0        0          0  \n",
       "9              0        0          0  \n",
       "10             0        0          0  \n",
       "11             0        0          0  \n",
       "12             0        0          0  \n",
       "13             0        0          0  \n",
       "14             0        0          0  \n",
       "15             0        0          0  \n",
       "16             0        0          0  \n",
       "17             0        0          0  \n",
       "18             0        0          0  \n",
       "19             0        0          0  \n",
       "20             0        0          0  \n",
       "21             0        0          0  \n",
       "22             0        0          0  \n",
       "23             0        0          0  \n",
       "24             0        0          0  \n",
       "25             0        0          0  \n",
       "26             0        0          0  \n",
       "27             0        0          0  \n",
       "28             0        0          0  \n",
       "29             0        0          0  \n",
       "30             0        0          0  \n",
       "31             0        0          0  \n",
       "32             0        0          0  \n",
       "33             0        0          0  \n",
       "34             0        0          0  \n",
       "35             0        0          0  \n",
       "36             0        0          0  \n",
       "37             0        0          0  \n",
       "38             0        0          0  \n",
       "39             0        0          0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "results.to_csv(f\"results/results_{prior.name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "27f3840d2a8e92b9098d5d1f2625c1fbd9e0739b6ace23f817bf68ad3a8d77b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
