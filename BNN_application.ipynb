{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Damja\\\\OneDrive\\\\Damjan\\\\HS22\\\\Deep Learning\\\\project\\\\dev'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import Subset\n",
    "from torch.distributions import Categorical, Normal, StudentT\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as tr\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import calibration_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import deque, OrderedDict\n",
    "from tqdm import trange\n",
    "import tqdm\n",
    "import copy\n",
    "import typing\n",
    "from typing import Sequence, Optional, Callable, Tuple, Dict, Union\n",
    "import pandas as pd\n",
    "\n",
    "from data import Data\n",
    "from priors import *\n",
    "from Networks import *\n",
    "from BayesianNN import BNN_MCMC\n",
    "from SGLD import SGLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  60000\n",
      "Test data size:  10000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset with specified transforms\n",
    "# possible transforms: RandomRotation, RandomCrop, GaussianBlur\n",
    "# avoid Normalize and ToTensor (already done), RandomHorizontalFlip (for MNIST), RandomVerticalFlip (for MNIST)\n",
    "augmentations = tr.Compose([tr.RandomRotation(15)])\n",
    "\n",
    "train_data, test_data = Data(\"MNIST\", augmentations = None).get_data(num_train_samples=60000)\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f72b71d6f1e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormal_Inverse_Gamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBNN_MCMC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFullyConnectedNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mburn_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Damja\\OneDrive\\Damjan\\HS22\\Deep Learning\\project\\dev\\BayesianNN.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                         \u001b[0mlog_prior\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Damja\\OneDrive\\Damjan\\HS22\\Deep Learning\\project\\dev\\priors.py\u001b[0m in \u001b[0;36mlog_likelihood\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# according to formula on wikipedia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mpart1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlam\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mpart2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[0mpart3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mpart4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlam\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "prior = Normal_Inverse_Gamma(0, 1, 1, 1)\n",
    "lol = BNN_MCMC(train_data, network = FullyConnectedNN(), prior=prior, num_epochs = 30, max_size = 15, burn_in = 5, lr = 1e-3, sample_interval = 2)\n",
    "lol.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-402028dd0bc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mece\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_calibration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test ECE: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lol' is not defined"
     ]
    }
   ],
   "source": [
    "acc = lol.test_accuracy(test_data)\n",
    "ece = lol.test_calibration(test_data)\n",
    "print(\"Test accuracy: \", acc)\n",
    "print(\"Test ECE: \", ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights from all models\n",
    "param_flat_all = []\n",
    "for model in lol.model_sequence:\n",
    "    parameters = model.state_dict()\n",
    "    param_values = list(parameters.values())\n",
    "    param_flat = torch.cat([v.flatten() for v in param_values])\n",
    "    param_flat_all.append(param_flat.flatten())\n",
    "\n",
    "# put all weights in one array\n",
    "params = np.concatenate(param_flat_all)\n",
    "\n",
    "# plot weights\n",
    "plt.hist(params, bins=1000, range=(-4, 4))\n",
    "plt.title(\"Weights of all models, GaussianMixture(-2, 0.5, 2, 0.5) \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, var = Normal_Inverse_Gamma(0, 1, 1, 1).sample(100000)\n",
    "x = x.flatten().numpy()\n",
    "var = var\n",
    "\n",
    "# plot prior samples\n",
    "plt.hist(x, bins=1000, range=(-5, 5))\n",
    "plt.show()\n",
    "\n",
    "# plot prior samples\n",
    "print(var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 15.01it/s, acc=0.125, log_prior_normalized=8.24e+4, loss=8.25e+4, lr=0.000183, nll_loss=10.7] \n"
     ]
    }
   ],
   "source": [
    "# pretrain on FashionMNIST\n",
    "pretrain_data, pretest_data = Data(\"FashionMNIST\", augmentations = None).get_data(num_train_samples=600)\n",
    "\n",
    "prior = Isotropic_Gaussian()\n",
    "pretrainer = BNN_MCMC(pretrain_data, network = FullyConnectedNN(), prior=prior, num_epochs = 30, max_size = 15, burn_in = 5, lr = 1e-3, sample_interval = 2)\n",
    "pretrainer.train()\n",
    "\n",
    "# get pretrained prior parameters\n",
    "mu, var = pretrainer.get_posterior_stats()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\OneDrive\\Dokumente\\Universität\\Master\\HS22\\Deep Learning\\Project\\Coding\\Priors.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.loc = torch.tensor(loc, dtype=torch.float32)\n",
      "c:\\Users\\jorge\\OneDrive\\Dokumente\\Universität\\Master\\HS22\\Deep Learning\\Project\\Coding\\Priors.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.scale = torch.tensor(scale, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "pretrained_Isotropic_Gaussian = Isotropic_Gaussian(mu, var)\n",
    "\n",
    "prior_list = [Isotropic_Gaussian(),\n",
    "              StudentT_prior(),\n",
    "              Laplace_prior(),\n",
    "              Gaussian_Mixture(), \n",
    "              GaussianSpikeNSlab(),\n",
    "              MixedLaplaceUniform(), \n",
    "              Normal_Inverse_Gamma()]\n",
    "\n",
    "prior_list_v2 = [Isotropic_Gaussian,\n",
    "              StudentT_prior,\n",
    "              Laplace_prior,\n",
    "              Gaussian_Mixture, \n",
    "              GaussianSpikeNSlab,\n",
    "              MixedLaplaceUniform, \n",
    "              Normal_Inverse_Gamma]\n",
    "\n",
    "sample_sizes = [3750, 7500, 15000, 30000, 60000, 120000]\n",
    "\n",
    "Temperatures = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "\n",
    "prior_list = [] \n",
    "for prior in prior_list_v2:\n",
    "    for temp in Temperatures:\n",
    "        prior_list.append(prior(Temperature=temp))\n",
    "        \n",
    "# prior list is then list of all priors initialized with the correpsonding temperature\n",
    "# [prior1_temp1, prior2_temp1, ..., prior7_temp1, prior1_temp2, prior2_temp2, ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prior</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test ECE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prior Sample Size Test Accuracy Test ECE\n",
       "0    NaN         NaN           NaN      NaN\n",
       "1    NaN         NaN           NaN      NaN\n",
       "2    NaN         NaN           NaN      NaN\n",
       "3    NaN         NaN           NaN      NaN\n",
       "4    NaN         NaN           NaN      NaN\n",
       "5    NaN         NaN           NaN      NaN\n",
       "6    NaN         NaN           NaN      NaN\n",
       "7    NaN         NaN           NaN      NaN\n",
       "8    NaN         NaN           NaN      NaN\n",
       "9    NaN         NaN           NaN      NaN\n",
       "10   NaN         NaN           NaN      NaN\n",
       "11   NaN         NaN           NaN      NaN\n",
       "12   NaN         NaN           NaN      NaN\n",
       "13   NaN         NaN           NaN      NaN\n",
       "14   NaN         NaN           NaN      NaN\n",
       "15   NaN         NaN           NaN      NaN\n",
       "16   NaN         NaN           NaN      NaN\n",
       "17   NaN         NaN           NaN      NaN\n",
       "18   NaN         NaN           NaN      NaN\n",
       "19   NaN         NaN           NaN      NaN\n",
       "20   NaN         NaN           NaN      NaN\n",
       "21   NaN         NaN           NaN      NaN\n",
       "22   NaN         NaN           NaN      NaN\n",
       "23   NaN         NaN           NaN      NaN\n",
       "24   NaN         NaN           NaN      NaN\n",
       "25   NaN         NaN           NaN      NaN\n",
       "26   NaN         NaN           NaN      NaN\n",
       "27   NaN         NaN           NaN      NaN\n",
       "28   NaN         NaN           NaN      NaN\n",
       "29   NaN         NaN           NaN      NaN\n",
       "30   NaN         NaN           NaN      NaN\n",
       "31   NaN         NaN           NaN      NaN\n",
       "32   NaN         NaN           NaN      NaN\n",
       "33   NaN         NaN           NaN      NaN\n",
       "34   NaN         NaN           NaN      NaN\n",
       "35   NaN         NaN           NaN      NaN\n",
       "36   NaN         NaN           NaN      NaN\n",
       "37   NaN         NaN           NaN      NaN\n",
       "38   NaN         NaN           NaN      NaN\n",
       "39   NaN         NaN           NaN      NaN\n",
       "40   NaN         NaN           NaN      NaN\n",
       "41   NaN         NaN           NaN      NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preallocate pandas dataframe for results\n",
    "results = pd.DataFrame(columns = [\"Prior\", \"Sample Size\", \"Temperature\", \"Test Accuracy\", \"Test ECE\"], index = range(len(prior_list)*len(sample_sizes)))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Isotropic Gaussian\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:12<00:00,  3.89it/s, acc=0.898, log_prior_normalized=8.27e+4, loss=8.27e+4, lr=0.000141, nll_loss=13.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8783)\n",
      "Test ECE:  tensor(0.1307)\n",
      "--------------------------------------------------\n",
      "Student-T\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:15<00:00,  3.24it/s, acc=0.852, log_prior_normalized=8.49e+4, loss=8.49e+4, lr=0.000141, nll_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8770)\n",
      "Test ECE:  tensor(0.1516)\n",
      "--------------------------------------------------\n",
      "Laplace\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:15<00:00,  3.25it/s, acc=0.109, log_prior_normalized=6.28e+4, loss=6.29e+4, lr=0.000141, nll_loss=67.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.1135)\n",
      "Test ECE:  tensor(0.0128)\n",
      "--------------------------------------------------\n",
      "Gaussian Mixture\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:20<00:00,  2.41it/s, acc=0.898, log_prior_normalized=1.51e+5, loss=1.51e+5, lr=0.000141, nll_loss=10.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8860)\n",
      "Test ECE:  tensor(0.0764)\n",
      "--------------------------------------------------\n",
      "Gaussian Spike and Slab\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:34<00:00,  1.45it/s, acc=0.922, log_prior_normalized=1.03e+5, loss=1.03e+5, lr=0.000141, nll_loss=12.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8770)\n",
      "Test ECE:  tensor(0.1293)\n",
      "--------------------------------------------------\n",
      "Mixed Laplace and Uniform\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:13<00:00,  3.59it/s, acc=0.922, log_prior_normalized=1.24e+5, loss=1.24e+5, lr=0.000141, nll_loss=6.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8859)\n",
      "Test ECE:  tensor(0.0308)\n",
      "--------------------------------------------------\n",
      "Normal Inverse Gamma\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.94it/s, acc=0.938, log_prior_normalized=70.4, loss=75.9, lr=0.000141, nll_loss=5.31]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8824)\n",
      "Test ECE:  tensor(0.0256)\n",
      "--------------------------------------------------\n",
      "Isotropic Gaussian\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:28<00:00,  1.78it/s, acc=0.891, log_prior_normalized=8.27e+4, loss=8.27e+4, lr=0.000141, nll_loss=19.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9059)\n",
      "Test ECE:  tensor(0.0768)\n",
      "--------------------------------------------------\n",
      "Student-T\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:41<00:00,  1.21it/s, acc=0.922, log_prior_normalized=8.49e+4, loss=8.5e+4, lr=0.000141, nll_loss=17.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9101)\n",
      "Test ECE:  tensor(0.0784)\n",
      "--------------------------------------------------\n",
      "Laplace\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:31<00:00,  1.59it/s, acc=0.0469, log_prior_normalized=6.28e+4, loss=6.3e+4, lr=0.000141, nll_loss=135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.0992)\n",
      "Test ECE:  tensor(0.0016)\n",
      "--------------------------------------------------\n",
      "Gaussian Mixture\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:38<00:00,  1.31it/s, acc=0.922, log_prior_normalized=1.52e+5, loss=1.52e+5, lr=0.000141, nll_loss=12.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9170)\n",
      "Test ECE:  tensor(0.0259)\n",
      "--------------------------------------------------\n",
      "Gaussian Spike and Slab\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:13<00:00,  1.46s/it, acc=0.922, log_prior_normalized=1.03e+5, loss=1.03e+5, lr=0.000141, nll_loss=17.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9078)\n",
      "Test ECE:  tensor(0.0759)\n",
      "--------------------------------------------------\n",
      "Mixed Laplace and Uniform\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.68it/s, acc=0.977, log_prior_normalized=1.24e+5, loss=1.24e+5, lr=0.000141, nll_loss=5.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9181)\n",
      "Test ECE:  tensor(0.0066)\n",
      "--------------------------------------------------\n",
      "Normal Inverse Gamma\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:33<00:00,  1.48it/s, acc=0.969, log_prior_normalized=41.7, loss=48.3, lr=0.000141, nll_loss=5.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9154)\n",
      "Test ECE:  tensor(0.0258)\n",
      "--------------------------------------------------\n",
      "Isotropic Gaussian\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:09<00:00,  1.39s/it, acc=0.945, log_prior_normalized=8.27e+4, loss=8.28e+4, lr=0.000141, nll_loss=26.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9296)\n",
      "Test ECE:  tensor(0.1705)\n",
      "--------------------------------------------------\n",
      "Student-T\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:16<00:00,  1.53s/it, acc=0.961, log_prior_normalized=8.5e+4, loss=8.5e+4, lr=0.000141, nll_loss=21.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8979)\n",
      "Test ECE:  tensor(0.1898)\n",
      "--------------------------------------------------\n",
      "Laplace\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:02<00:00,  1.25s/it, acc=0.117, log_prior_normalized=6.28e+4, loss=6.31e+4, lr=0.000141, nll_loss=270] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.1135)\n",
      "Test ECE:  tensor(0.0104)\n",
      "--------------------------------------------------\n",
      "Gaussian Mixture\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:13<00:00,  1.46s/it, acc=0.984, log_prior_normalized=1.52e+5, loss=1.52e+5, lr=0.000141, nll_loss=11.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9444)\n",
      "Test ECE:  tensor(0.0762)\n",
      "--------------------------------------------------\n",
      "Gaussian Spike and Slab\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:28<00:00,  2.98s/it, acc=0.938, log_prior_normalized=1.03e+5, loss=1.03e+5, lr=0.000141, nll_loss=27.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9334)\n",
      "Test ECE:  tensor(0.1509)\n",
      "--------------------------------------------------\n",
      "Mixed Laplace and Uniform\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:54<00:00,  1.09s/it, acc=0.984, log_prior_normalized=1.24e+5, loss=1.24e+5, lr=0.000141, nll_loss=5.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9412)\n",
      "Test ECE:  tensor(0.0153)\n",
      "--------------------------------------------------\n",
      "Normal Inverse Gamma\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:05<00:00,  1.31s/it, acc=0.984, log_prior_normalized=30.1, loss=41.1, lr=0.000141, nll_loss=9.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9335)\n",
      "Test ECE:  tensor(0.0203)\n",
      "--------------------------------------------------\n",
      "Isotropic Gaussian\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:47<00:00,  2.15s/it, acc=0.977, log_prior_normalized=8.27e+4, loss=8.28e+4, lr=0.000141, nll_loss=22.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9634)\n",
      "Test ECE:  tensor(0.1056)\n",
      "--------------------------------------------------\n",
      "Student-T\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:10<00:00,  2.61s/it, acc=0.953, log_prior_normalized=8.5e+4, loss=8.5e+4, lr=0.000141, nll_loss=31.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9630)\n",
      "Test ECE:  tensor(0.0825)\n",
      "--------------------------------------------------\n",
      "Laplace\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:57<00:00,  2.36s/it, acc=0.883, log_prior_normalized=6.29e+4, loss=6.3e+4, lr=0.000141, nll_loss=95.3]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.8517)\n",
      "Test ECE:  tensor(0.2947)\n",
      "--------------------------------------------------\n",
      "Gaussian Mixture\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:24<00:00,  2.88s/it, acc=0.992, log_prior_normalized=1.52e+5, loss=1.52e+5, lr=0.000141, nll_loss=11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9666)\n",
      "Test ECE:  tensor(0.0353)\n",
      "--------------------------------------------------\n",
      "Gaussian Spike and Slab\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:41<00:00,  5.63s/it, acc=0.969, log_prior_normalized=1.03e+5, loss=1.03e+5, lr=0.000141, nll_loss=40.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9643)\n",
      "Test ECE:  tensor(0.0857)\n",
      "--------------------------------------------------\n",
      "Mixed Laplace and Uniform\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:45<00:00,  2.12s/it, acc=1, log_prior_normalized=1.24e+5, loss=1.24e+5, lr=0.000141, nll_loss=1.81]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9598)\n",
      "Test ECE:  tensor(0.0117)\n",
      "--------------------------------------------------\n",
      "Normal Inverse Gamma\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:11<00:00,  2.63s/it, acc=0.992, log_prior_normalized=17.3, loss=34.6, lr=0.000141, nll_loss=12.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9579)\n",
      "Test ECE:  tensor(0.0124)\n",
      "--------------------------------------------------\n",
      "Isotropic Gaussian\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:34<00:00,  4.30s/it, acc=0.992, log_prior_normalized=8.27e+4, loss=8.28e+4, lr=0.000141, nll_loss=21.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9761)\n",
      "Test ECE:  tensor(0.0306)\n",
      "--------------------------------------------------\n",
      "Student-T\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:19<00:00,  5.20s/it, acc=0.992, log_prior_normalized=8.5e+4, loss=8.5e+4, lr=0.000141, nll_loss=16.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9755)\n",
      "Test ECE:  tensor(0.0344)\n",
      "--------------------------------------------------\n",
      "Laplace\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:59<00:00,  4.79s/it, acc=0.945, log_prior_normalized=6.3e+4, loss=6.31e+4, lr=0.000141, nll_loss=80.7]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9233)\n",
      "Test ECE:  tensor(0.1213)\n",
      "--------------------------------------------------\n",
      "Gaussian Mixture\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:47<00:00,  5.75s/it, acc=0.992, log_prior_normalized=1.52e+5, loss=1.52e+5, lr=0.000141, nll_loss=15.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9785)\n",
      "Test ECE:  tensor(0.0200)\n",
      "--------------------------------------------------\n",
      "Gaussian Spike and Slab\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [09:24<00:00, 11.30s/it, acc=0.984, log_prior_normalized=1.03e+5, loss=1.03e+5, lr=0.000141, nll_loss=30.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9768)\n",
      "Test ECE:  tensor(0.0364)\n",
      "--------------------------------------------------\n",
      "Mixed Laplace and Uniform\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:31<00:00,  4.23s/it, acc=1, log_prior_normalized=1.24e+5, loss=1.24e+5, lr=0.000141, nll_loss=6.83]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9738)\n",
      "Test ECE:  tensor(0.0092)\n",
      "--------------------------------------------------\n",
      "Normal Inverse Gamma\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:24<00:00,  5.29s/it, acc=0.992, log_prior_normalized=14.1, loss=48.8, lr=0.000141, nll_loss=28.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  tensor(0.9684)\n",
      "Test ECE:  tensor(0.0091)\n",
      "--------------------------------------------------\n",
      "Isotropic Gaussian\n",
      "Training Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:33<08:38, 11.04s/it, acc=0.992, log_prior_normalized=82800.0, loss=8.29e+4, lr=0.00097, nll_loss=26.2]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m# run BNN\u001b[39;00m\n\u001b[0;32m     20\u001b[0m lol \u001b[39m=\u001b[39m BNN_MCMC(train_data, network \u001b[39m=\u001b[39m FullyConnectedNN(), prior\u001b[39m=\u001b[39mprior, num_epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m, max_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, burn_in \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m, lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m, sample_interval \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m lol\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m     23\u001b[0m \u001b[39m# get test accuracy and ECE\u001b[39;00m\n\u001b[0;32m     24\u001b[0m acc \u001b[39m=\u001b[39m lol\u001b[39m.\u001b[39mtest_accuracy(test_data)\n",
      "File \u001b[1;32mc:\\Users\\jorge\\OneDrive\\Dokumente\\Universität\\Master\\HS22\\Deep Learning\\Project\\Coding\\BayesianNN.py:76\u001b[0m, in \u001b[0;36mBNN_MCMC.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m progress_bar:\n\u001b[0;32m     74\u001b[0m     num_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (batch_x, batch_y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loader):\n\u001b[0;32m     77\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     78\u001b[0m         n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch_x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the experiment for all priors\n",
    "\n",
    "#create a dict for the different parameter values\n",
    "base_epoch, base_burn_in, base_sample_interval, base_samplesize = 50, 15, 2, sample_sizes[-1]\n",
    "args_dict = [(sample_size, (base_epoch*base_samplesize/sample_size, base_burn_in*base_samplesize/sample_size, base_sample_interval*base_samplesize/sample_size )) for sample_size in sample_sizes]\n",
    "args_dict = dict(args_dict)\n",
    "\n",
    "\n",
    "for n in range(len(sample_sizes)):\n",
    "    # get data\n",
    "    if sample_sizes[n] == 120000:\n",
    "        # if sample size is 120000, use data augmentation\n",
    "        augmentations = tr.Compose([tr.RandomRotation(15)])\n",
    "        train_data, test_data = Data(\"MNIST\", augmentations = augmentations).get_data()\n",
    "    else:\n",
    "        # subsample original train data if sample size is smaller than 120000\n",
    "        train_data, test_data = Data(\"MNIST\", augmentations = None).get_data(num_train_samples=sample_sizes[n])\n",
    "    \n",
    "    for i in range(len(prior_list)):\n",
    "        # get prior\n",
    "        prior = prior_list[i]\n",
    "        print(50*\"-\")\n",
    "        print(prior.name)\n",
    "        print(prior.Temperature)\n",
    "\n",
    "        # run BNN\n",
    "        lol = BNN_MCMC(\n",
    "            train_data,\n",
    "            network = FullyConnectedNN(),\n",
    "            prior=prior,\n",
    "            num_epochs = args_dict[sample_sizes[n]][0],\n",
    "            max_size = 10,\n",
    "            burn_in = args_dict[sample_sizes[n]][1],\n",
    "            lr = 1e-3,\n",
    "            sample_interval = args_dict[sample_sizes[n]][2])\n",
    "\n",
    "        lol.train()\n",
    "\n",
    "        # get test accuracy and ECE\n",
    "        acc = lol.test_accuracy(test_data)\n",
    "        ece = lol.test_calibration(test_data)\n",
    "        print(\"Test accuracy: \", acc)\n",
    "        print(\"Test ECE: \", ece)\n",
    "\n",
    "        # save results\n",
    "        results.iloc[i+n*len(prior_list), :] = prior.name, sample_sizes[n], prior.Temperature, acc.numpy(), ece.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prior</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test ECE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isotropic Gaussian</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.13070764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student-T</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.15161534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.012761287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian Mixture</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.076357536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Spike and Slab</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.12927525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mixed Laplace and Uniform</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.03075873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal Inverse Gamma</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.025573293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isotropic Gaussian</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.07683899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Student-T</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.078380935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.0015765876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gaussian Mixture</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.025904007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaussian Spike and Slab</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>0.07590773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mixed Laplace and Uniform</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.0065603107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Normal Inverse Gamma</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.025835032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Isotropic Gaussian</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>0.17045754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Student-T</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.18984672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.010420799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gaussian Mixture</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.076178655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gaussian Spike and Slab</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.15086322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mixed Laplace and Uniform</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.015250945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Normal Inverse Gamma</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.02031873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Isotropic Gaussian</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.10564047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Student-T</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.08254508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.2947402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gaussian Mixture</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.035334423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gaussian Spike and Slab</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.08572714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mixed Laplace and Uniform</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.011715608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Normal Inverse Gamma</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.012375807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Isotropic Gaussian</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.030575624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Student-T</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.034446634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.121263616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gaussian Mixture</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.020032894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gaussian Spike and Slab</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.03639191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Mixed Laplace and Uniform</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.009217366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Normal Inverse Gamma</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.009091823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Prior Sample Size Test Accuracy      Test ECE\n",
       "0          Isotropic Gaussian        3750        0.8783    0.13070764\n",
       "1                   Student-T        3750         0.877    0.15161534\n",
       "2                     Laplace        3750        0.1135   0.012761287\n",
       "3            Gaussian Mixture        3750         0.886   0.076357536\n",
       "4     Gaussian Spike and Slab        3750         0.877    0.12927525\n",
       "5   Mixed Laplace and Uniform        3750        0.8859    0.03075873\n",
       "6        Normal Inverse Gamma        3750        0.8824   0.025573293\n",
       "7          Isotropic Gaussian        7500        0.9059    0.07683899\n",
       "8                   Student-T        7500        0.9101   0.078380935\n",
       "9                     Laplace        7500        0.0992  0.0015765876\n",
       "10           Gaussian Mixture        7500         0.917   0.025904007\n",
       "11    Gaussian Spike and Slab        7500        0.9078    0.07590773\n",
       "12  Mixed Laplace and Uniform        7500        0.9181  0.0065603107\n",
       "13       Normal Inverse Gamma        7500        0.9154   0.025835032\n",
       "14         Isotropic Gaussian       15000        0.9296    0.17045754\n",
       "15                  Student-T       15000        0.8979    0.18984672\n",
       "16                    Laplace       15000        0.1135   0.010420799\n",
       "17           Gaussian Mixture       15000        0.9444   0.076178655\n",
       "18    Gaussian Spike and Slab       15000        0.9334    0.15086322\n",
       "19  Mixed Laplace and Uniform       15000        0.9412   0.015250945\n",
       "20       Normal Inverse Gamma       15000        0.9335    0.02031873\n",
       "21         Isotropic Gaussian       30000        0.9634    0.10564047\n",
       "22                  Student-T       30000         0.963    0.08254508\n",
       "23                    Laplace       30000        0.8517     0.2947402\n",
       "24           Gaussian Mixture       30000        0.9666   0.035334423\n",
       "25    Gaussian Spike and Slab       30000        0.9643    0.08572714\n",
       "26  Mixed Laplace and Uniform       30000        0.9598   0.011715608\n",
       "27       Normal Inverse Gamma       30000        0.9579   0.012375807\n",
       "28         Isotropic Gaussian       60000        0.9761   0.030575624\n",
       "29                  Student-T       60000        0.9755   0.034446634\n",
       "30                    Laplace       60000        0.9233   0.121263616\n",
       "31           Gaussian Mixture       60000        0.9785   0.020032894\n",
       "32    Gaussian Spike and Slab       60000        0.9768    0.03639191\n",
       "33  Mixed Laplace and Uniform       60000        0.9738   0.009217366\n",
       "34       Normal Inverse Gamma       60000        0.9684   0.009091823\n",
       "35                        NaN         NaN           NaN           NaN\n",
       "36                        NaN         NaN           NaN           NaN\n",
       "37                        NaN         NaN           NaN           NaN\n",
       "38                        NaN         NaN           NaN           NaN\n",
       "39                        NaN         NaN           NaN           NaN\n",
       "40                        NaN         NaN           NaN           NaN\n",
       "41                        NaN         NaN           NaN           NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print full pandas dataframe\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa526d89aec0a31945a2b2620e49fa7082f45611cb01c48b28f8969ea0ac1514"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
