{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.distributions import Categorical, Normal, StudentT\n",
    "from torch.optim import SGD\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "import tqdm\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "transform = transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample from trainset\n",
    "n_subsamples_train = 2000 # size of subset\n",
    "sub_train_idx = random.sample(range(60000),n_subsamples_train) # 60'000 is train size in MNSIT\n",
    "sub_train_set = Subset(train_set, sub_train_idx)\n",
    "\n",
    "# subsample from testset\n",
    "n_subsamples_test = 1000  # size of subset\n",
    "sub_test_idx = random.sample(range(10000), n_subsamples_test) # 10'000 is test size in MNIST\n",
    "sub_test_set = Subset(test_set, sub_test_idx)\n",
    "\n",
    "# load\n",
    "#sub_train_dataloader = DataLoader(sub_train_set, batch_size=64, shuffle=True)\n",
    "sub_test_dataloader = DataLoader(sub_test_set, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick Check \n",
    "feature_test = sub_test_set[999][0]\n",
    "label_test = sub_test_set[999][1]\n",
    "print(label_test)\n",
    "plt.imshow(feature_test.squeeze(), cmap='hot')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "feature_train = sub_train_set[1999][0]\n",
    "label_train = sub_train_set[1999][1]\n",
    "print(label_train)\n",
    "plt.imshow(feature_train.squeeze(), cmap='hot')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Model Part Krause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Class for Priors\n",
    "\n",
    "class Prior:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def sample(self,n):\n",
    "        pass\n",
    "    def log_likelihood(self,values):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gaussian Prior\n",
    "# Change: to a subclass of Prior\n",
    "\n",
    "class IsotropicGaussian(Prior):\n",
    "    def __init__(self, mean=0, std=1):\n",
    "        super(IsotropicGaussian,self).__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def sample(self, n):\n",
    "        return np.random.normal(self.mean, self.std, size=n)\n",
    "\n",
    "    def log_likelihood(self, weights):\n",
    "        return Normal(self.mean, self.std).log_prob(torch.tensor(weights)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Neural Network \n",
    "\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, in_features = 28*28, out_features = 10, hidden_units = 100, hidden_layers = 3):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.Linear(in_features, hidden_units))\n",
    "        for i in range(hidden_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_units, hidden_units))\n",
    "        self.output_layer = nn.Linear(hidden_units, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,28*28)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "        class_probs = self.output_layer(x)\n",
    "        return class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework\n",
    "\n",
    "class Framework(object):\n",
    "    def __init__(self, training_set, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Basic Framework for your bayesian neural network.\n",
    "        SGLD will be based on this.\n",
    "        \"\"\"\n",
    "        self.train_set = training_set\n",
    "        self.print_interval = 64 # number of batches until updated metrics are displayed during training\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, data_loader: torch.utils.data.DataLoader) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict the class probabilities using your trained model.\n",
    "        This method should return an (num_samples, 10) NumPy float array\n",
    "        such that the second dimension sums up to 1 for each row.\n",
    "\n",
    "        :param data_loader: Data loader yielding the samples to predict on\n",
    "        :return: (num_samples, 10) NumPy float array where the second dimension sums up to 1 for each row\n",
    "        \"\"\"\n",
    "        probability_batches = []\n",
    "        \n",
    "        for batch_x, _ in tqdm.tqdm(data_loader):\n",
    "            current_probabilities = self.predict_probabilities(batch_x).detach().numpy()\n",
    "            probability_batches.append(current_probabilities)\n",
    "\n",
    "        output = np.concatenate(probability_batches, axis=0)\n",
    "        assert isinstance(output, np.ndarray)\n",
    "        assert output.ndim == 2 and output.shape[1] == 10\n",
    "        assert np.allclose(np.sum(output, axis=1), 1.0)\n",
    "        return output\n",
    "\n",
    "    def predict_probabilities(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGLD(SGD):\n",
    "    \"\"\"Implementation of SGLD algorithm.\n",
    "\n",
    "    Paper: \"Bayesian Learning via Stochastic Gradient Langevin Dynamics\", Welling & Teh, 2011.\n",
    "    ----------\n",
    "        \n",
    "    \"\"\"\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None, prior = IsotropicGaussian()):\n",
    "        \"\"\"See `torch.optim.step’.\"\"\"\n",
    "        loss = super().step(closure)\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad_p = p.grad.data\n",
    "                #log_prior_weights = prior.log_likelihood(p.data)    # LOG_LIKELIHOOD OF WEIGHTS WITH PRIOR DISTRIBUTION\n",
    "                #cost_and_regular = grad_p + log_prior_weights      # SUM OF THE TWO\n",
    "                if weight_decay!=0:\n",
    "                    grad_p.add_(alpha=weight_decay,other=p.data)\n",
    "                langevin_noise = torch.randn_like(p.data).mul_(group['lr']**0.5)*0.1 #  use weight 0.1 to balance the noise\n",
    "                p.data.add_(grad_p,alpha=-0.5*group['lr'])\n",
    "                #p.data.add_(cost_and_regular,alpha=-0.5*group['lr'])\n",
    "                if torch.isnan(p.data).any(): \n",
    "                    exit('Exist NaN param after SGLD, Try to tune the parameter')\n",
    "                if torch.isinf(p.data).any(): \n",
    "                    exit('Exist Inf param after SGLD, Try to tune the parameter')\n",
    "                p.data.add_(langevin_noise)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# LOOK AT SKRIPT PAI AT PAGE 130/118 FOR THE ALGORITHM TO IMPLEMENT IT BY YOURSELF #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGLDTrainer(Framework):\n",
    "    def __init__(self, dataset_train, prior = IsotropicGaussian(), *args, **kwargs):\n",
    "        super().__init__(dataset_train, *args, **kwargs)\n",
    "\n",
    "        # Hyperparameters and general parameters\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 1e-3\n",
    "        self.num_epochs = 300\n",
    "        self.burn_in = 10\n",
    "        self.sample_interval = 1\n",
    "        self.max_size = 100\n",
    "        \n",
    "        self.data_loader = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "\n",
    "        # Set Prior\n",
    "        self.prior = prior\n",
    "\n",
    "        # Initialize the SGLD network\n",
    "        self.network = FullyConnectedNN()\n",
    "\n",
    "        # SGLD optimizer is provided\n",
    "        self.optimizer = SGLD(self.network.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Deque to store model samples\n",
    "        self.SGLDSequence = deque()\n",
    "\n",
    "    def train(self):\n",
    "        num_iter = 0\n",
    "        print('Training model')\n",
    "\n",
    "        self.network.train()\n",
    "        progress_bar = trange(self.num_epochs)\n",
    "\n",
    "        for _ in progress_bar:\n",
    "            num_iter += 1\n",
    "\n",
    "            for batch_idx, (batch_x, batch_y) in enumerate(self.data_loader):\n",
    "                self.network.zero_grad()\n",
    "\n",
    "                # Perform forward pass\n",
    "                current_logits = self.network(batch_x)\n",
    "\n",
    "                # Calculate log_likelihood of weights for a given prior\n",
    "\n",
    "                parameters = self.network.state_dict()     # extract weights from network\n",
    "                param_values = list(parameters.values())    # list weights\n",
    "                param_flat = np.concatenate([v.flatten() for v in param_values])    # flattern\n",
    "                log_likelihood = self.prior.log_likelihood(param_flat)              # calculate log_lik\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = F.nll_loss(F.log_softmax(current_logits, dim=1), batch_y) - log_likelihood\n",
    "\n",
    "                # Backpropagate to get the gradients\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if batch_idx % self.print_interval == 0:\n",
    "                    current_logits = self.network(batch_x)\n",
    "                    current_accuracy = (current_logits.argmax(axis=1) == batch_y).float().mean()\n",
    "                    progress_bar.set_postfix(loss=loss.item(), acc=current_accuracy.item())\n",
    "  \n",
    "            # Save the model samples if past the burn-in epochs and reached a regular sampling interval\n",
    "            if num_iter > self.burn_in and num_iter % self.sample_interval == 0:\n",
    "                self.SGLDSequence.append(copy.deepcopy(self.network))\n",
    "                # self.network.state_dict()\n",
    "\n",
    "            # If the deque exceeds the maximum size, delete the oldest model\n",
    "            if len(self.SGLDSequence) > self.max_size:\n",
    "                self.SGLDSequence.popleft()\n",
    "\n",
    "    def predict_probabilities(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #assert x.shape[1] == 28 ** 2\n",
    "        self.network.eval()\n",
    "\n",
    "        # Obtain the prediction from each network in SGLDSequence and combine the predictions\n",
    "        estimated_probability = torch.zeros((len(x), 10))\n",
    "        for model in self.SGLDSequence:\n",
    "\n",
    "\n",
    "            self.network.load_state_dict(model.state_dict())\n",
    "            logits = self.network(x).detach()\n",
    "            estimated_probability += F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Normalize the combined predictions\n",
    "        estimated_probability /= len(self.SGLDSequence)\n",
    "\n",
    "        assert estimated_probability.shape == (x.shape[0], 10)  \n",
    "        return estimated_probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:12<00:00,  1.04s/it, acc=0.891, loss=9.64e+4]\n"
     ]
    }
   ],
   "source": [
    "lol = SGLDTrainer(sub_train_set)\n",
    "lol.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "x_test = sub_test_set.dataset.data.float()\n",
    "y_test = sub_test_set.dataset.targets\n",
    "\n",
    "# predicted probabilities\n",
    "class_probs = lol.predict_probabilities(x_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = (class_probs.argmax(axis=1) == y_test).float().mean()\n",
    "print(f'Test Accuracy: {accuracy.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration Error: 0.0200\n"
     ]
    }
   ],
   "source": [
    "# Calibration\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import calibration_error\n",
    "\n",
    "calib_err = calibration_error(class_probs, y_test, n_bins = 30, task = \"multiclass\", norm=\"l1\", num_classes=10)\n",
    "print(f'Calibration Error: {calib_err.item():.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with special Prior lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniform at the middle, Laplace at the sides, 50% weight on uniform, 25% weight each side.\n",
    "\n",
    "#   a = e/4\n",
    "#   if x < -1:              f(x) = e/4*exp(x)\n",
    "#   if -1 <= x <= 1:        f(x) = 1/4\n",
    "#   if x > 1:               f(x) = e/4*exp(-x)\n",
    "\n",
    "##\n",
    "\n",
    "class MixedLaplaceUniform(Prior):\n",
    "    def __init__(self):\n",
    "        self.a = np.exp(1)/4\n",
    "\n",
    "    def sample(self, size=1) -> torch.tensor:\n",
    "        \"\"\"Generates samples from the mixed probability distribution.\"\"\"\n",
    "        samples = np.zeros(size)\n",
    "        for i in range(size):\n",
    "            u = np.random.uniform(0,1)\n",
    "            if u < 1/4:\n",
    "                samples[i] = np.log(u/self.a)   # Solved CDF to sample x \n",
    "            elif u <= 3/4:\n",
    "                samples[i] = (u - 1/4)*4 - 1            # Solved CDF to sample x\n",
    "            else:\n",
    "                b = 1/np.exp(1) - ((u-0.75)/self.a)\n",
    "                c = 1/b\n",
    "                samples[i] = np.log(c)\n",
    "        return torch.tensor(samples)\n",
    "        \n",
    "    def log_likelihood(self, values: torch.tensor) -> torch.tensor:\n",
    "        log_values = []\n",
    "        for value in values:\n",
    "            if value < -1:\n",
    "                val = value + np.log(self.a)\n",
    "                log_values.append(val)\n",
    "            elif value <= 1:\n",
    "                val = torch.tensor(np.log(1/4))\n",
    "                log_values.append(val)\n",
    "            else:\n",
    "                val = -value +np.log(self.a)\n",
    "                log_values.append(val)\n",
    "\n",
    "        return sum(log_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/300 [14:57<8:03:23, 99.67s/it, acc=0.0781, loss=1.38e+5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/1981778128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnödlol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGLDTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_train_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMixedLaplaceUniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnödlol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/506096285.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mparam_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# list weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mparam_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# flattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0mlog_likelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_flat\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# calculate log_lik\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;31m# Calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/1385589019.py\u001b[0m in \u001b[0;36mlog_likelihood\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mlog_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[0mlog_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nödlol = SGLDTrainer(sub_train_set, prior=MixedLaplaceUniform())\n",
    "nödlol.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (Temp/ipykernel_5496/1108157369.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\bimib\\AppData\\Local\\Temp/ipykernel_5496/1108157369.py\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    return StudentT(self.df, self.mu, self.rho).sample(torch.tensor(n)))  # sample from student-T\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "class StudentTPrior(Prior):\n",
    "    \"\"\"\n",
    "    Student-T Prior\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: torch.Tensor, rho: torch.Tensor, Temperature: float= 1.0, df: torch.Tensor = 10):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.mu = mu\n",
    "        self.rho = rho\n",
    "        self.rho = torch.log(1 + torch.exp(rho))  # transform rho\n",
    "        self.Temperature = Temperature\n",
    "\n",
    "    def log_likelihood(self, values: torch.Tensor) -> torch.Tensor:\n",
    "        return StudentT(self.df, self.mu, self.rho).log_prob(values).sum() / self.Temperature\n",
    "\n",
    "    def sample(self,n) -> torch.Tensor:\n",
    "        return StudentT(self.df, self.mu, self.rho).sample(torch.tensor(n)))  # sample from student-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/2171712433.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mStudentTPrior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5496/1053418249.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mStudentT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# sample from student-T\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\bimib\\anaconda3\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, sample_shape)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bimib\\anaconda3\\lib\\site-packages\\torch\\distributions\\studentT.py\u001b[0m in \u001b[0;36mrsample\u001b[1;34m(self, sample_shape)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m#   Z ~ Chi2(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m#   Y = X / sqrt(Z / df) ~ StudentT(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_standard_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_chi2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bimib\\anaconda3\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m_extended_shape\u001b[1;34m(self, sample_shape)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \"\"\"\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0msample_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "df = torch.tensor(10)\n",
    "mu = torch.tensor(0)\n",
    "rho = torch.tensor(10)\n",
    "StudentTPrior(df=df,mu=mu,rho=rho).sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vlt_lol = SGLDTrainer(sub_train_set, prior=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17f2fa85e4cfd485d54f024c1b8a04817ed39643e0edc5d72a4881a916b82e72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
